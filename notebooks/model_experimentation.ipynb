{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilidade de infecção por agente infeccioso\n",
    "Como vimos durante a análise exploratória, cerca de 54% dos casos de SRAGs no \n",
    "Brasil não possuem uma conclusão sobre o agente infeccioso. Por isso, vamos\n",
    "treinar um modelo de classificação para tentar prever qual o agente infeccioso\n",
    "de um caso de SRAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import mlflow\n",
    "import optuna\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Preprocessing\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import log_loss, f1_score, confusion_matrix, recall_score, precision_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures, PowerTransformer\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os dados\n",
    "data = pd.read_csv(\"../data/raw/INFLUD23-16-10-2023.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nem todas as colunas disponíveis no dataset serão utilizadas para a \n",
    "classificação. Após avaliação inicial, as seguintes colunas foram\n",
    "selecionadas para a classificação: DT_SIN_PRI, SEM_NOT, SEM_PRI, SG_UF_NOT, \n",
    "ESTRANG, NU_IDADE_N, POV_CT, SG_UF, CS_ZONA, OUT_ANIM, FEBRE, TOSSE, GARGANTA, \n",
    "DISPNEIA, DESC_RESP, SATURACAO, DIARREIA, VOMITO, DOR_ABD, FADIGA, PERD_OLF, \n",
    "PERD_PALA, OUTRO_SIN, OUTRO_DES, VACINA, DOSE_2REF, CLASSI_FIN, CLASSI_OUT.\n",
    "\n",
    "Primeiro, temos a data dos primeiros sintomas (DT_SIN_PRI) e a semana de\n",
    "primeiros sintomas (SEM_PRI) em conjunto com a semana da notificação (SEM_NOT). \n",
    "Tais colunas foram selecionadas por certos agentes infecciosos possuirem \n",
    "sazonalidade, como é o caso do vírus influenza. As variáveis de idade \n",
    "(NU_IDADE_N), estado (SG_UF), estrangeiro (ESTRANG) e zona (CS_ZONA) foram \n",
    "selecionadas por serem variáveis demográficas que podem influenciar na \n",
    "probabilidade de infecção. Outra que pode influenciar é se o paciente teve \n",
    "contato com certos animais (OUT_ANIM). As variáveis de sintomas (FEBRE, TOSSE, \n",
    "GARGANTA, DISPNEIA, DESC_RESP, SATURACAO, DIARREIA, VOMITO, DOR_ABD, FADIGA, \n",
    "PERD_OLF, PERD_PALA, OUTRO_SIN, OUTRO_DES) foram selecionadas por serem \n",
    "sintomas comuns de SRAGs. Por último, as variáveis de vacinação (VACINA, \n",
    "DOSE_2REF) foram selecionadas por serem variáveis que revelam se o paciente foi \n",
    "vacinado contra certos agentes infecciosos. \n",
    "\n",
    "As variáveis de classificação (CLASSI_FIN, CLASSI_OUT) foram selecionadas por\n",
    "serem as variáveis que queremos prever. A variável CLASSI_FIN é a classificação\n",
    "final do caso, enquanto CLASSI_OUT é um complemento. Ambas serão unidas em uma\n",
    "única variável, chamada CLASSI, que será a variável alvo do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando lista com as colunas selecionadas\n",
    "colunas_selecionadas = [\"DT_SIN_PRI\", \"SEM_PRI\", \"ESTRANG\", \n",
    "\"SEM_NOT\", \"NU_IDADE_N\", \"SG_UF\", \"CS_ZONA\", \"OUT_ANIM\", \"FEBRE\", \"TOSSE\", \n",
    "\"GARGANTA\", \"DISPNEIA\", \"DESC_RESP\", \"SATURACAO\", \"DIARREIA\", \"VOMITO\", \n",
    "\"DOR_ABD\", \"FADIGA\", \"PERD_OLFT\", \"PERD_PALA\", \"OUTRO_SIN\", \"OUTRO_DES\", \n",
    "\"VACINA\", \"VACINA_COV\", \"DOSE_2REF\", \"CLASSI_FIN\", \"CLASSI_OUT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscando as colunas selecionadas\n",
    "data = data[colunas_selecionadas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os dados\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as dimensões do dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o Pandas Profilling para gerar um report sobre os dados e assim decidir qual caminho seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gerando o report\n",
    "#profile = ProfileReport(data, title=\"Pandas Profiling Report\")\n",
    "#profile.to_file(\"../images/reports/INFLUD23-16-10-2023.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base no relatório, as seguintes modificações serão feitas:\n",
    "- Selecionar apenas os registros com o agente infeccioso definido;\n",
    "- Alterar o tipo das colunas DT_SIN_PRI e DOSE_2REF para datetime;\n",
    "- Deletar os registros negativos da coluna NU_IDADE_N (Não existe idade negativa);\n",
    "- Por ter 99.7% de missing, a coluna OUT_ANIM será deletada;\n",
    "- Expandir a coluna OUTRO_DES para gerar novas colunas com sintomas;\n",
    "- Unir a coluna CLASSI_OUT com a coluna CLASSI_FIN;\n",
    "- Alterar todos os valores numéricos das colunas para o seu real valor;\n",
    "- Corrigir os valores  e ausentes da coluna CLASSI_FIN;\n",
    "\n",
    "Insights gerais:\n",
    "- 28% dos dados estão ausentes.\n",
    "- 0.4% dos dados são duplicados.\n",
    "- Temos um problema de classificação com multiplos rótulos.\n",
    "\n",
    "Por ter muitos valores únicos e em baixa quantidade, selecionaremos apenas os\n",
    "targets com mais de 100 registros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando as correções no dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando apenas os registros com o agente infeccioso definido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando apenas os casos identificados\n",
    "data = data.query(\"CLASSI_FIN != 4.0\")\n",
    "\n",
    "# Dropando os registros com valores nulos no target\n",
    "data = data.dropna(subset=[\"CLASSI_FIN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alterando o tipo das colunas DT_SIN_PRI e DOSE_2REF para datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando o tipo dos dados\n",
    "data[\"DT_SIN_PRI\"] = pd.to_datetime(data[\"DT_SIN_PRI\"], format=\"%d/%m/%Y\")\n",
    "data[\"DOSE_2REF\"] = pd.to_datetime(data[\"DOSE_2REF\"], format=\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deletar os registros negativos da coluna NU_IDADE_N (Não existe idade negativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscando apenas os registros com idade maior ou igual a zero\n",
    "data = data.query(\"NU_IDADE_N >= 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por ter 99.7% de missing, a coluna OUT_ANIM será deletada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando a coluna\n",
    "data = data.drop(\"OUT_ANIM\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expandir a coluna OUTRO_DES para gerar novas colunas com sintomas\n",
    "\n",
    "RESULTADO: Esta abordagem não surtiu muito efeito, a sequência permanecerá \n",
    "comentada para não afetar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"OUTRO_DES\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando uma bag com os sintomas\n",
    "#lista_sintomas_inicial = []\n",
    "#\n",
    "## Obtendo apenas os sintomas sem espaço no nome\n",
    "#for sintomas in data[\"OUTRO_DES\"].dropna():\n",
    "#    if sintomas.find(\" \") == -1:\n",
    "#        lista_sintomas_inicial.append(sintomas)\n",
    "#    else:\n",
    "#        continue\n",
    "#\n",
    "## Obtendo os sintomas sem caracteres especiais no nome\n",
    "#lista_sintomas_final = []\n",
    "#for sintomas in lista_sintomas_inicial:\n",
    "#    if re.search(\"[^a-zA-Z0-9]\", sintomas) == None:\n",
    "#        lista_sintomas_final.append(sintomas)\n",
    "#    else:\n",
    "#        continue\n",
    "#\n",
    "## Obter os sintomas únicos\n",
    "#lista_sintomas_final = list(set(lista_sintomas_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando um dicionário com listas vazia\n",
    "#dict_sintomas = {sintoma:lista for sintoma, lista in zip(lista_sintomas_final, [[] for i in range(len(lista_sintomas_final))])}\n",
    "#\n",
    "## Verificando se a string do sintoma contém algum dos sintomas\n",
    "#for sintomas in data[\"OUTRO_DES\"]:\n",
    "#    if sintomas is np.nan:\n",
    "#        for key, value in dict_sintomas.items():\n",
    "#            value.append(0)\n",
    "#    \n",
    "#    else:\n",
    "#        for sintoma in lista_sintomas_final:\n",
    "#            if sintomas.__contains__(sintoma):\n",
    "#                dict_sintomas[sintoma].append(1)\n",
    "#            else:\n",
    "#                dict_sintomas[sintoma].append(0)\n",
    "#                \n",
    "## Criando um dataframe com os sintomas\n",
    "#data_sintomas_extra = pd.DataFrame(dict_sintomas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Buscando as colunas com baixa variância\n",
    "#drop_constant = DropConstantFeatures(tol=0.998)\n",
    "#drop_constant.fit(data_sintomas_extra)\n",
    "#features_to_maintain = [column for column in data_sintomas_extra.columns if column not in drop_constant.features_to_drop_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropando as colunas com baixa variância\n",
    "#data_sintomas_extra = data_sintomas_extra[features_to_maintain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropando a coluna\n",
    "#data = data.drop(\"OUTRO_DES\", axis = 1)\n",
    "#\n",
    "## Concatenando os dataframes\n",
    "#data = pd.concat([data, data_sintomas_extra], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unir a coluna CLASSI_OUT com a coluna CLASSI_FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando os valores numéricos para os nomes das categorias\n",
    "dict_novas_cat = {1.0:\"Influenza\",\n",
    "                  2.0:\"Outro vírus\",\n",
    "                  3.0:3.0,\n",
    "                  5.0:\"Covid-19\"}\n",
    "\n",
    "# Aplicando a mudança\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].map(dict_novas_cat)\n",
    "\n",
    "# Buscando as classes complementares\n",
    "data.loc[data[\"CLASSI_FIN\"] == 3, \"CLASSI_FIN\"] = data.loc[data[\"CLASSI_FIN\"] == 3, \"CLASSI_OUT\"]\n",
    "\n",
    "# Dropando a coluna CLASSI_OUT\n",
    "data = data.drop(\"CLASSI_OUT\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alterar todos os valores numéricos das colunas para o seu real valor;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando as funções\n",
    "func_estrangeiro = lambda num: \"Sim\" if num == 1 else \"Não\"\n",
    "func_zona = lambda num: \"Urbana\" if num == 1 else (\"Rural\" if num == 2 else (\"Periurbana\" if num == 3 else \"Ignorado\"))\n",
    "func_sintoma_and_vacina = lambda num: \"Sim\" if num == 1 else (\"Não\" if num == 2 else \"Ignorado\")\n",
    "\n",
    "# Aplicando as alterações\n",
    "data[\"ESTRANG\"] = data[\"ESTRANG\"].apply(func_estrangeiro)\n",
    "data[\"CS_ZONA\"] = data[\"CS_ZONA\"].apply(func_zona)\n",
    "\n",
    "# Criando uma lista com os sintomas\n",
    "sintomas = [\"FEBRE\", \"TOSSE\", \"GARGANTA\", \"DISPNEIA\", \"DESC_RESP\", \"SATURACAO\", \n",
    "            \"DIARREIA\", \"VOMITO\", \"DOR_ABD\", \"FADIGA\", \"PERD_OLFT\", \n",
    "            \"PERD_PALA\", \"OUTRO_SIN\"]\n",
    "\n",
    "# Aplicando as alterações\n",
    "for sintoma in sintomas:\n",
    "    data[sintoma] = data[sintoma].apply(func_sintoma_and_vacina)\n",
    "    \n",
    "# Criando uma lista com as vacinas\n",
    "vacinas = [\"VACINA\", \"VACINA_COV\"]\n",
    "for vacina in vacinas:\n",
    "    data[vacina] = data[vacina].apply(func_sintoma_and_vacina)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrigir os valores  e ausentes da coluna CLASSI_FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletando os targets ausentes\n",
    "data = data.dropna(subset=[\"CLASSI_FIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outros = [\"pneumonia\", \"PNEUMONIA COMUNITARIA\", \n",
    "          \"broncopnm em paciente com enfi\", \"klebsiella pneumonie\", \n",
    "          \"PNEUMONITE BRONCOASPIRATIVA\", \"PNEUMONITE DEVIDA A ALIMENTO\",\n",
    "          \"DPOC , PNM BRONCOASPIRATIVA\", \"SINDROME GRIPAL, BRONQUIOPNEUM\",\n",
    "          \"PNM BACTERIANA GRAN NEGAT\", \"PNM - IRA\", \"PNM INTRAHOSPITALAR\",\n",
    "          \"PNM , IRPA\", \"PNEMUMONIA\", \"PNEUMOCYSTIS JIROVECII\", \n",
    "          \"PN BACTERIANA\", \"PNM FUNGICA\", \"PNM NOSOCOMIAL AVC\", \"PMEUMONIA\",\n",
    "          \"PNEUMONIO COMUNITARIA\", \"PNM BACTERIANA BRONCOASPIRATIV\", \n",
    "          \"PNEUMINA\", \"PNEUMONIA BACTERIANA\", \"PNEUMONIA - DPOC\",\n",
    "          \"PNEUMONIA BACTERIA\", \"PNEUMONIA NAO ESPECIFICADA J18\",\n",
    "          \"CID J18, PNEUMONIA\", \"BRONCOESPASMO/PNEUMONIA\", \n",
    "          \"MYCOPLASMA PNEUMONIAE\", \"STREPTOCOCCUS PNEUMOIAL\", \n",
    "          \"PNM INTRA HOSPITALASR\", \"PNEUMONIA CID J18, BRONQUIOLIT\",\n",
    "          \"SRAG - PNEUMOCISTOSE\", \"PNEUMONIA POR STAPHYLO AUREUS\", \n",
    "          \"SEPSES PULMONAR, PNEUMONIA ,\", \"PNEUMONIA, CA\", \n",
    "          \"PNEUMONIA, ASMA\", \"PNEUMONIA BACTERIANA NAO ESPEC\", \n",
    "          \"CID= J18 PNEUMONIA\", \"PNEMOCISTOSE.PNEUMONIA POR CMV\", \n",
    "          \"PNEUMON IA\", \"IRA - PNEUMONIA\", \"IRA - PNEUMONIA\",\n",
    "          \"PNEUMONIA - BRONCOESPASMO\", \"PNM VIRAL/ COINF. BACTERIANA\", \n",
    "          \"IRA,PNM\", \"PNEUMONIA\", \"STREPTOCOCCUS PNEUMONIAE\", \"PNM\",\n",
    "          \"PNEUMONIA VIRAL\", \"PNM BACTERIANA\", \"PNEUMONIA NAO ESPECIFICADA\",\n",
    "          \"Outro vírus\", \"HIV\", \"DENGUE\", \"TUBERCULOSE\", \n",
    "          \"MYCOBACTERIUM TUBERCULOSIS\", \"MICROBACTERIA TUBERCULOSE\", \n",
    "          \"TEBERCULOSE\", \"MYCOBACTERIUM TUBERCULOSIS,\", \n",
    "          \"TUBERCULOSE (M. TUBERCULOSIS)\", \n",
    "          \"TUBERCULOSE POSITIVO BAAR\", \"MYCOBACTERIUM TUBERCULOSIS\", \"TB\",\n",
    "          \"TUBERCULOSE PULMONAR\", \"VIRUS SINCICIAL RESPIRATORIO]\", \n",
    "          \"VIRUS SINCIAL RESPIRATORIO\", \"VIRUS SINCICIAL RESPIRATORIO\", \n",
    "          \"VIRUS SINCICIAL\"]\n",
    "\n",
    "covids = [\"Covid-19\", \"CORNOVIRUS OC43\", \"CORONAVIRUS NL63\", \"\"]\n",
    "\n",
    "influenzas = [\"Influenza\", \"H1N1\", \"HAEMOFILOS INFLUENZA\", \"H INFLUENZAE\"]\n",
    "\n",
    "# Criando funções para agrupar agentes semelhantes\n",
    "func_agrupar_covid = lambda doenca: \"Covid-19\" if doenca in covids else doenca\n",
    "func_agrupar_influenza = lambda doenca: \"Influenza\" if doenca in influenzas else doenca\n",
    "func_agrupar_outros = lambda doenca: \"Outro vírus\" if doenca in outros else doenca\n",
    "\n",
    "# Aplicando as funções\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].apply(func_agrupar_covid)\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].apply(func_agrupar_influenza)\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].apply(func_agrupar_outros)\n",
    "\n",
    "# Capturando apenas os registros com doenças conhecidas\n",
    "data = data.query(f\"CLASSI_FIN in {['Covid-19', 'Influenza', 'Outro vírus']}\")\n",
    "\n",
    "# Mapeia o target para numérico\n",
    "dict_target = {\"Covid-19\":0, \"Influenza\":1, \"Outro vírus\":2}\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].map(dict_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engenharia de Features\n",
    "\n",
    "Aqui, irei criar as seguintes features:\n",
    "- Tempo decorrido entre os primeiros sintomas e a notificação;\n",
    "- Tempo decorrido entre a vacinação da gripe e os primeiros sintomas;\n",
    "- Diferença entre a data dos primeiros sintomas e a data de reforço para covid;\n",
    "- Verificar de qual região é o estado do paciente;\n",
    "- Se ele apresenta multiplos sintomas;\n",
    "- Mês do primeiro sintoma e da vacina;\n",
    "- Se os sintomas apareceram na primeira ou segunda quinzena do mês;\n",
    "- Se a vacina foi na primeira ou segunda quinzena do mês;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a diferença entre as semanas epidemiológicas\n",
    "data[\"diferenca_semana_epi\"] = data[\"SEM_NOT\"] - data[\"SEM_PRI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculando a diferença de dias entre a data de vacinação da covid e a data de sintomas\n",
    "data['DIFERENCA_DIAS_REF_COVID'] = (data['DT_SIN_PRI'] - data['DOSE_2REF']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista com as UF de cada região\n",
    "regiao_sul = [\"PR\", \"SC\", \"RS\"]\n",
    "regiao_sudeste = [\"SP\", \"RJ\", \"MG\", \"ES\"]\n",
    "regiao_centro_oeste = [\"MS\", \"MT\", \"GO\", \"DF\"]\n",
    "regiao_norte = [\"RO\", \"AC\", \"AM\", \"RR\", \"PA\", \"AP\", \"TO\"]\n",
    "\n",
    "# Criando uma função para identificar a região\n",
    "func_regiao = lambda uf: \"Sul\" if uf in regiao_sul else(\"Sudeste\" if uf in regiao_sudeste else(\"Centro-Oeste\" if uf in regiao_centro_oeste else(\"Norte\" if uf in regiao_norte else \"Nordeste\")))\n",
    "data[\"REGIAO\"] = data[\"SG_UF\"].apply(func_regiao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contando a quantidade de sintomas que o paciente apresentou\n",
    "data[\"MAIS_DE_UM_SINTOMA\"] = data[sintomas].apply(lambda x: x.str.contains(\"Sim\").sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletando o mês\n",
    "data[\"MES_SIN\"] = data[\"DT_SIN_PRI\"].dt.month\n",
    "data[\"MES_VAC\"] = data[\"DOSE_2REF\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se o dia dos sintomas foi na primeira ou segunda quinzena do mês\n",
    "data[\"QUINZENA_SIN\"] = data[\"DT_SIN_PRI\"].apply(lambda x: \"Primeira\" if x.day <= 15 else \"Segunda\")\n",
    "data[\"QUINZENA_VAC\"] = data[\"DOSE_2REF\"].apply(lambda x: \"Primeira\" if x.day <= 15 else \"Segunda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando as colunas de data\n",
    "data = data.drop([\"DT_SIN_PRI\", \"DOSE_2REF\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o local para salvar os exoerimentos\n",
    "mlflow.set_tracking_uri('../mlruns')\n",
    "\n",
    "## Criando/acessando o experimento\n",
    "#mlflow.set_experiment('Comparando modelos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em variáveis dependentes e independentes\n",
    "x = data.drop(columns='CLASSI_FIN')\n",
    "y = data['CLASSI_FIN']\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x,\n",
    "                                                        y,\n",
    "                                                        test_size=0.30,\n",
    "                                                        random_state=200)\n",
    "\n",
    "# Dividindo os dados em teste e calibração\n",
    "x_teste, x_calib, y_teste, y_calib = train_test_split(x_teste,\n",
    "                                                      y_teste,\n",
    "                                                      test_size=0.35,\n",
    "                                                      random_state=200)\n",
    "\n",
    "# Dividindo os dados em dev e teste\n",
    "x_dev, x_teste, y_dev, y_teste = train_test_split(x_teste,\n",
    "                                                  y_teste,\n",
    "                                                  test_size=0.50,\n",
    "                                                  random_state=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo as colunas categóricas\n",
    "cat_cols = x.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Obtendo as colunas numéricas\n",
    "num_cols = x.select_dtypes(['int', 'float']).columns.tolist()\n",
    "\n",
    "# Instanciando um KFold Estratificado\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dicionário com os modelos\n",
    "dict_models_scale_sensitive = {\"LR\": LogisticRegression(random_state=200,\n",
    "                                                        class_weight='balanced',\n",
    "                                                        multi_class='auto')}\n",
    "\n",
    "dict_models_tree_based = {\"LGBM\": LGBMClassifier(is_unbalance=True,\n",
    "                                                 objective= 'multiclass',\n",
    "                                                 random_state=200),\n",
    "                          \"XGB\": XGBClassifier(random_state=200,\n",
    "                                               objective='multi:softprob'),\n",
    "                          \"RF\": RandomForestClassifier(class_weight='balanced',\n",
    "                                                       random_state=200)}\n",
    "\n",
    "# Criando dicionário com os encoders\n",
    "dict_encoders = {\"OHE\": OneHotEncoder(drop='first'),\n",
    "                 \"TE\": ce.TargetEncoder(),\n",
    "                 \"BE\": ce.BinaryEncoder(),\n",
    "                 \"ME\": ce.MEstimateEncoder(),\n",
    "                 \"CE\": ce.CatBoostEncoder(),\n",
    "                 \"GE\":ce.GrayEncoder()}\n",
    "\n",
    "dict_imputers_num = {\"SIAVG\": SimpleImputer(strategy='mean'),\n",
    "                     \"SIMEDIAN\": SimpleImputer(strategy='median')}\n",
    "\n",
    "dict_scalers = {\"SS\": StandardScaler()}\n",
    "\n",
    "# Criando dicionário com os transformers\n",
    "dict_transformers = {\"PT\": PowerTransformer(),\n",
    "                     \"PF\": PolynomialFeatures()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos sem transformers\n",
    "#for tag, model in dict_models_scale_sensitive.items():\n",
    "#    for tag_imputer, imputer in dict_imputers_num.items():\n",
    "#        for tag_encoder, encoder in dict_encoders.items():\n",
    "#            for tag_scaler, scaler in dict_scalers.items():\n",
    "#                \n",
    "#                # Gerando a tag de identificação do modelo\n",
    "#                nome_modelo = f'{tag}_{tag_imputer}_{tag_encoder}_{tag_scaler}'\n",
    "#                \n",
    "#                with mlflow.start_run(run_name=nome_modelo):\n",
    "#                    \n",
    "#                    # Criando os pipeline com os transformers\n",
    "#                    pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                                         ('encoder', encoder)])\n",
    "#                    \n",
    "#                    pipe_num = Pipeline([('imputer_num', imputer),\n",
    "#                                         ('scaler', scaler)])\n",
    "#                    \n",
    "#                    # Criando o transformador\n",
    "#                    transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                    ('num', pipe_num, num_cols)])\n",
    "#                    \n",
    "#                    # Criando o pipeline final\n",
    "#                    pipe = Pipeline([('transformer', transformer),\n",
    "#                                    ('model', model)])\n",
    "#                    \n",
    "#                    # Executando o cross validation\n",
    "#                    cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#                    \n",
    "#                    # Calculando a média das métricas\n",
    "#                    mean_score = cross_val_scores.mean()           \n",
    "#                    \n",
    "#                    # Salvando a métrica da folder 1\n",
    "#                    mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#                    \n",
    "#                    # Salvando a métrica da folder 2\n",
    "#                    mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#                    \n",
    "#                    # Salvando a métrica da folder 3\n",
    "#                    mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#                    \n",
    "#                    # Salvando a métrica da folder 4\n",
    "#                    mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#                    \n",
    "#                    # Salvando a métrica da folder 5\n",
    "#                    mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#                    \n",
    "#                    # Salvando as métricas\n",
    "#                    mlflow.log_metric('log_loss_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos com transformers\n",
    "#for tag, model in dict_models_scale_sensitive.items():\n",
    "#    for tag_imputer, imputer in dict_imputers_num.items():\n",
    "#        for tag_encoder, encoder in dict_encoders.items():\n",
    "#            for tag_scaler, scaler in dict_scalers.items():\n",
    "#                for tag_transformer, transformer in dict_transformers.items():\n",
    "#                \n",
    "#                    # Gerando a tag de identificação do modelo\n",
    "#                    nome_modelo = f'{tag}_{tag_imputer}_{tag_encoder}_{tag_scaler}_{tag_transformer}'\n",
    "#\n",
    "#                    with mlflow.start_run(run_name=nome_modelo):\n",
    "#                        \n",
    "#                        # Criando os pipeline com os transformers\n",
    "#                        pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                                             ('encoder', encoder)])\n",
    "#                    \n",
    "#                        pipe_num = Pipeline([('imputer_num', imputer),\n",
    "#                                             ('scaler', scaler),\n",
    "#                                             ('transformer', transformer)])\n",
    "#\n",
    "#                        # Criando o transformador\n",
    "#                        transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                        ('num', pipe_num, num_cols)])\n",
    "#\n",
    "#                        # Criando o pipeline final\n",
    "#                        pipe = Pipeline([('transformer', transformer),\n",
    "#                                        ('model', model)])\n",
    "#\n",
    "#                        # Executando o cross validation\n",
    "#                        cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#\n",
    "#                        # Calculando a média das métricas\n",
    "#                        mean_score = cross_val_scores.mean()         \n",
    "#\n",
    "#                        # Salvando a métrica da folder 1\n",
    "#                        mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#\n",
    "#                        # Salvando a métrica da folder 2\n",
    "#                        mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#\n",
    "#                        # Salvando a métrica da folder 3\n",
    "#                        mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#\n",
    "#                        # Salvando a métrica da folder 4\n",
    "#                        mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#\n",
    "#                        # Salvando a métrica da folder 5\n",
    "#                        mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#\n",
    "#                        # Salvando as métricas\n",
    "#                        mlflow.log_metric('log_loss_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos sem transformers\n",
    "#for tag, model in dict_models_tree_based.items():\n",
    "#    for tag_imputer, imputer in dict_imputers_num.items():\n",
    "#        for tag_encoder, encoder in dict_encoders.items():\n",
    "#\n",
    "#                # Gerando a tag de identificação do modelo\n",
    "#                nome_modelo = f'{tag}_{tag_imputer}_{tag_encoder}'\n",
    "#\n",
    "#                with mlflow.start_run(run_name=nome_modelo):\n",
    "#\n",
    "#                     # Criando os pipeline com os transformers\n",
    "#                     pipe_cat = Pipeline([('imputer_cat', SimpleImputer(strategy='most_frequent')),\n",
    "#                                          ('encoder', encoder)])\n",
    "#                     pipe_num = Pipeline([('imputer_num', imputer)])\n",
    "#\n",
    "#                     # Criando o transformador\n",
    "#                     transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                      ('num', pipe_num, num_cols)])\n",
    "#\n",
    "#                     # Criando o pipeline final\n",
    "#                     pipe = Pipeline([('transformer', transformer),\n",
    "#                                     ('model', model)])\n",
    "#\n",
    "#                     # Executando o cross validation\n",
    "#                     cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#\n",
    "#                     # Calculando a média das métricas\n",
    "#                     mean_score = cross_val_scores.mean()         \n",
    "#\n",
    "#                     # Salvando a métrica da folder 1\n",
    "#                     mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 2\n",
    "#                     mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 3\n",
    "#                     mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 4\n",
    "#                     mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 5\n",
    "#                     mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#\n",
    "#                     # Salvando as métricas\n",
    "#                     mlflow.log_metric('log_loss_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Busca a tabela com os resultados\n",
    "#resultados = mlflow.search_runs()\n",
    "#\n",
    "## calculando o tempo de treinamento em segundos\n",
    "#resultados['train_time_em_segundos'] = (resultados['end_time'] - resultados['start_time']).dt.seconds\n",
    "#\n",
    "## Buscando as colunas para retornar\n",
    "#colunas_para_retornar = ['tags.mlflow.runName', 'train_time_em_segundos', \n",
    "#                         'metrics.log_loss_fold_1', 'metrics.log_loss_fold_2', \n",
    "#                         'metrics.log_loss_fold_5', 'metrics.log_loss_fold_3', \n",
    "#                         'metrics.log_loss_fold_4', 'metrics.log_loss_mean']\n",
    "## Retornando os resultados ordenados pela média\n",
    "#resultados.loc[:, colunas_para_retornar].sort_values(by='metrics.log_loss_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E o nosso modelo campeão foi o **XGBoost** com uma média de **0.55** de \n",
    "<i>log loss</i>. O modelo foi acompanhado com os seguintes transformers:\n",
    "**OneHotEncoder** e **SimpleImputer** usando a **mediana**. Foi \n",
    "possível observar que todas as folds possuem um resultado muito próximo, o que \n",
    "indica que o modelo não está sofrendo de overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunando o modelo vencedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando função para tunar o modelo\n",
    "#def objective(trial):\n",
    "#\n",
    "#    params = {\n",
    "#            'objective':'multi:softprob',\n",
    "#            'eval_metric': 'logloss',\n",
    "#            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "#            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "#            'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "#            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "#            'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "#            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1)\n",
    "#        }\n",
    "#    \n",
    "#    # Criando os pipelines com os transformers\n",
    "#    pipe_cat = Pipeline([('imputer_cat', SimpleImputer(strategy='most_frequent')),\n",
    "#                        ('encoder', OneHotEncoder(drop='first'))])\n",
    "#    \n",
    "#    pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy='mean'))])\n",
    "#\n",
    "#    # Criando o transformador\n",
    "#    transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                     ('num', pipe_num, num_cols)])\n",
    "#\n",
    "#    # Criando o pipeline final\n",
    "#    pipe = Pipeline([('transformer', transformer),\n",
    "#                    ('rf', XGBClassifier(**params))])\n",
    "#\n",
    "#    # Treinando o modelo com os dados de treino\n",
    "#    pipe.fit(x_treino, y_treino)\n",
    "#   \n",
    "#    # Calculando a loss com os dados de desenvolvimento\n",
    "#    logloss = log_loss(y_dev, pipe.predict_proba(x_dev))\n",
    "#    \n",
    "#    return logloss\n",
    "#\n",
    "## Criando o estudo de otimização\n",
    "#study = optuna.create_study(direction = 'minimize')\n",
    "#study.optimize(objective, n_trials = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscando os melhores parâmetros\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente não houve uma melhora significativa no modelo. Devido a isso, iremos\n",
    "seguir com o modelo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o pipeline final\n",
    "pipe_cat = Pipeline([('imputer_cat', SimpleImputer(strategy='most_frequent')),\n",
    "                    ('encoder', OneHotEncoder(drop='first'))])\n",
    "pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy='median'))])\n",
    "\n",
    "# Criando o transformador\n",
    "transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "                                ('num', pipe_num, num_cols)])\n",
    "\n",
    "# Criando o pipeline final\n",
    "pipe = Pipeline([('transformer', transformer),\n",
    "                ('model', XGBClassifier(random_state=200,\n",
    "                                        objective='multi:softprob'))])\n",
    "\n",
    "# Treinando com os dados de treino\n",
    "pipe.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computando algumas métricas com os dados de teste\n",
    "print(f\"Log Loss: {log_loss(y_teste, pipe.predict_proba(x_teste))}\")\n",
    "print(f\"F1: {f1_score(y_teste, pipe.predict(x_teste), average='weighted')}\")\n",
    "print(f\"Precision: {precision_score(y_teste, pipe.predict(x_teste), average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(y_teste, pipe.predict(x_teste), average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das pessoas que o nosso modelo classificou com determinada doença, 77% delas \n",
    "realmente tinham a doença. Já dos que realmente tinham determinada doença, nosso\n",
    "modelo previu corretamente 78% delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_teste, pipe.predict(x_teste)), display_labels=['Covid-19', 'Influenza', 'Outro vírus']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É necessário melhorar o modelo para detectar melhor a Influenza."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
