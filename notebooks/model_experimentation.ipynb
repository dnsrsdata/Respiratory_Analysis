{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilidade de infecção por agente infeccioso\n",
    "Como vimos durante a análise exploratória, cerca de 54% dos casos de SRAGs no \n",
    "Brasil não possuem uma conclusão sobre o agente infeccioso. Por isso, vamos\n",
    "treinar um modelo de classificação para tentar prever qual o agente infeccioso\n",
    "de um caso de SRAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/Respiratory_Analysis/venv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/Respiratory_Analysis/venv/lib/python3.10/site-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import mlflow\n",
    "import optuna\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "from pycaret.classification import *\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from feature_engine.selection import DropConstantFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures, PowerTransformer\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os dados\n",
    "data = pd.read_csv(\"../data/raw/INFLUD23-16-10-2023.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nem todas as colunas disponíveis no dataset serão utilizadas para a \n",
    "classificação. Após avaliação inicial, as seguintes colunas foram\n",
    "selecionadas para a classificação: DT_SIN_PRI, SEM_NOT, SEM_PRI, SG_UF_NOT, \n",
    "ESTRANG, NU_IDADE_N, POV_CT, SG_UF, CS_ZONA, OUT_ANIM, FEBRE, TOSSE, GARGANTA, \n",
    "DISPNEIA, DESC_RESP, SATURACAO, DIARREIA, VOMITO, DOR_ABD, FADIGA, PERD_OLF, \n",
    "PERD_PALA, OUTRO_SIN, OUTRO_DES, VACINA, DOSE_2REF, CLASSI_FIN, CLASSI_OUT.\n",
    "\n",
    "Primeiro, temos a data dos primeiros sintomas (DT_SIN_PRI) e a semana de\n",
    "primeiros sintomas (SEM_PRI) em conjunto com a semana da notificação (SEM_NOT). \n",
    "Tais colunas foram selecionadas por certos agentes infecciosos possuirem \n",
    "sazonalidade, como é o caso do vírus influenza. As variáveis de idade \n",
    "(NU_IDADE_N), estado (SG_UF), estrangeiro (ESTRANG) e zona (CS_ZONA) foram \n",
    "selecionadas por serem variáveis demográficas que podem influenciar na \n",
    "probabilidade de infecção. Outra que pode influenciar é se o paciente teve \n",
    "contato com certos animais (OUT_ANIM). As variáveis de sintomas (FEBRE, TOSSE, \n",
    "GARGANTA, DISPNEIA, DESC_RESP, SATURACAO, DIARREIA, VOMITO, DOR_ABD, FADIGA, \n",
    "PERD_OLF, PERD_PALA, OUTRO_SIN, OUTRO_DES) foram selecionadas por serem \n",
    "sintomas comuns de SRAGs. Por último, as variáveis de vacinação (VACINA, \n",
    "DOSE_2REF) foram selecionadas por serem variáveis que revelam se o paciente foi \n",
    "vacinado contra certos agentes infecciosos. \n",
    "\n",
    "As variáveis de classificação (CLASSI_FIN, CLASSI_OUT) foram selecionadas por\n",
    "serem as variáveis que queremos prever. A variável CLASSI_FIN é a classificação\n",
    "final do caso, enquanto CLASSI_OUT é um complemento. Ambas serão unidas em uma\n",
    "única variável, chamada CLASSI, que será a variável alvo do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando lista com as colunas selecionadas\n",
    "colunas_selecionadas = [\"DT_SIN_PRI\", \"SEM_PRI\", \"ESTRANG\", \n",
    "\"SEM_NOT\", \"NU_IDADE_N\", \"SG_UF\", \"CS_ZONA\", \"OUT_ANIM\", \"FEBRE\", \"TOSSE\", \n",
    "\"GARGANTA\", \"DISPNEIA\", \"DESC_RESP\", \"SATURACAO\", \"DIARREIA\", \"VOMITO\", \n",
    "\"DOR_ABD\", \"FADIGA\", \"PERD_OLFT\", \"PERD_PALA\", \"OUTRO_SIN\", \"OUTRO_DES\", \n",
    "\"VACINA\", \"VACINA_COV\", \"DOSE_2REF\", \"CLASSI_FIN\", \"CLASSI_OUT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscando as colunas selecionadas\n",
    "data = data[colunas_selecionadas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT_SIN_PRI</th>\n",
       "      <th>SEM_PRI</th>\n",
       "      <th>ESTRANG</th>\n",
       "      <th>SEM_NOT</th>\n",
       "      <th>NU_IDADE_N</th>\n",
       "      <th>SG_UF</th>\n",
       "      <th>CS_ZONA</th>\n",
       "      <th>OUT_ANIM</th>\n",
       "      <th>FEBRE</th>\n",
       "      <th>TOSSE</th>\n",
       "      <th>...</th>\n",
       "      <th>FADIGA</th>\n",
       "      <th>PERD_OLFT</th>\n",
       "      <th>PERD_PALA</th>\n",
       "      <th>OUTRO_SIN</th>\n",
       "      <th>OUTRO_DES</th>\n",
       "      <th>VACINA</th>\n",
       "      <th>VACINA_COV</th>\n",
       "      <th>DOSE_2REF</th>\n",
       "      <th>CLASSI_FIN</th>\n",
       "      <th>CLASSI_OUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17/01/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>MG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/04/2022</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>RJ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/05/2022</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/01/2023</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>SP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19/04/2022</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18/01/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>SP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FRAQUEZA,MAL ESTAR,MIALGIA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/02/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25/05/2022</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DT_SIN_PRI  SEM_PRI  ESTRANG  SEM_NOT  NU_IDADE_N SG_UF  CS_ZONA OUT_ANIM  \\\n",
       "0  17/01/2023        3      2.0        3          75    MG      1.0      NaN   \n",
       "1  01/01/2023        1      2.0        1          67    RJ      1.0      NaN   \n",
       "2  05/01/2023        1      NaN        2          72    SP      1.0      NaN   \n",
       "3  18/01/2023        3      2.0        4          46    SP      1.0      NaN   \n",
       "4  03/02/2023        5      2.0        6          71    SP      NaN      NaN   \n",
       "\n",
       "   FEBRE  TOSSE  ...  FADIGA  PERD_OLFT  PERD_PALA  OUTRO_SIN  \\\n",
       "0    1.0    1.0  ...     1.0        2.0        2.0        2.0   \n",
       "1    1.0    9.0  ...     9.0        9.0        9.0        9.0   \n",
       "2    2.0    1.0  ...     2.0        2.0        2.0        2.0   \n",
       "3    1.0    2.0  ...     2.0        2.0        2.0        1.0   \n",
       "4    NaN    1.0  ...     2.0        2.0        2.0        NaN   \n",
       "\n",
       "                    OUTRO_DES  VACINA  VACINA_COV   DOSE_2REF  CLASSI_FIN  \\\n",
       "0                         NaN     1.0         1.0  11/04/2022         4.0   \n",
       "1                         NaN     9.0         1.0  10/05/2022         4.0   \n",
       "2                         NaN     NaN         1.0  19/04/2022         5.0   \n",
       "3  FRAQUEZA,MAL ESTAR,MIALGIA     2.0         1.0         NaN         4.0   \n",
       "4                         NaN     1.0         1.0  25/05/2022         4.0   \n",
       "\n",
       "   CLASSI_OUT  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os dados\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226763, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando as dimensões do dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar o Pandas Profilling para gerar um report sobre os dados e assim decidir qual caminho seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gerando o report\n",
    "#profile = ProfileReport(data, title=\"Pandas Profiling Report\")\n",
    "#profile.to_file(\"../images/reports/INFLUD23-16-10-2023.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base no relatório, as seguintes modificações serão feitas:\n",
    "- Selecionar apenas os registros com o agente infeccioso definido;\n",
    "- Alterar o tipo das colunas DT_SIN_PRI e DOSE_2REF para datetime;\n",
    "- Deletar os registros negativos da coluna NU_IDADE_N (Não existe idade negativa);\n",
    "- Por ter 99.7% de missing, a coluna OUT_ANIM será deletada;\n",
    "- Expandir a coluna OUTRO_DES para gerar novas colunas com sintomas;\n",
    "- Unir a coluna CLASSI_OUT com a coluna CLASSI_FIN;\n",
    "- Alterar todos os valores numéricos das colunas para o seu real valor;\n",
    "- Corrigir os valores  e ausentes da coluna CLASSI_FIN;\n",
    "\n",
    "Insights gerais:\n",
    "- 28% dos dados estão ausentes.\n",
    "- 0.4% dos dados são duplicados.\n",
    "- Temos um problema de classificação com multiplos rótulos.\n",
    "\n",
    "Por ter muitos valores únicos e em baixa quantidade, selecionaremos apenas os\n",
    "targets com mais de 100 registros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando as correções no dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando apenas os registros com o agente infeccioso definido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando apenas os casos identificados\n",
    "data = data.query(\"CLASSI_FIN != 4.0\")\n",
    "\n",
    "# Dropando os registros com valores nulos no target\n",
    "data = data.dropna(subset=[\"CLASSI_FIN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alterando o tipo das colunas DT_SIN_PRI e DOSE_2REF para datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando o tipo dos dados\n",
    "data[\"DT_SIN_PRI\"] = pd.to_datetime(data[\"DT_SIN_PRI\"], format=\"%d/%m/%Y\")\n",
    "data[\"DOSE_2REF\"] = pd.to_datetime(data[\"DOSE_2REF\"], format=\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deletar os registros negativos da coluna NU_IDADE_N (Não existe idade negativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscando apenas os registros com idade maior ou igual a zero\n",
    "data = data.query(\"NU_IDADE_N >= 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por ter 99.7% de missing, a coluna OUT_ANIM será deletada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando a coluna\n",
    "data = data.drop(\"OUT_ANIM\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expandir a coluna OUTRO_DES para gerar novas colunas com sintomas\n",
    "\n",
    "RESULTADO: Esta abordagem não surtiu muito efeito, a sequência permanecerá \n",
    "comentada para não afetar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"OUTRO_DES\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando uma bag com os sintomas\n",
    "#lista_sintomas_inicial = []\n",
    "#\n",
    "## Obtendo apenas os sintomas sem espaço no nome\n",
    "#for sintomas in data[\"OUTRO_DES\"].dropna():\n",
    "#    if sintomas.find(\" \") == -1:\n",
    "#        lista_sintomas_inicial.append(sintomas)\n",
    "#    else:\n",
    "#        continue\n",
    "#\n",
    "## Obtendo os sintomas sem caracteres especiais no nome\n",
    "#lista_sintomas_final = []\n",
    "#for sintomas in lista_sintomas_inicial:\n",
    "#    if re.search(\"[^a-zA-Z0-9]\", sintomas) == None:\n",
    "#        lista_sintomas_final.append(sintomas)\n",
    "#    else:\n",
    "#        continue\n",
    "#\n",
    "## Obter os sintomas únicos\n",
    "#lista_sintomas_final = list(set(lista_sintomas_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando um dicionário com listas vazia\n",
    "#dict_sintomas = {sintoma:lista for sintoma, lista in zip(lista_sintomas_final, [[] for i in range(len(lista_sintomas_final))])}\n",
    "#\n",
    "## Verificando se a string do sintoma contém algum dos sintomas\n",
    "#for sintomas in data[\"OUTRO_DES\"]:\n",
    "#    if sintomas is np.nan:\n",
    "#        for key, value in dict_sintomas.items():\n",
    "#            value.append(0)\n",
    "#    \n",
    "#    else:\n",
    "#        for sintoma in lista_sintomas_final:\n",
    "#            if sintomas.__contains__(sintoma):\n",
    "#                dict_sintomas[sintoma].append(1)\n",
    "#            else:\n",
    "#                dict_sintomas[sintoma].append(0)\n",
    "#                \n",
    "## Criando um dataframe com os sintomas\n",
    "#data_sintomas_extra = pd.DataFrame(dict_sintomas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Buscando as colunas com baixa variância\n",
    "#drop_constant = DropConstantFeatures(tol=0.998)\n",
    "#drop_constant.fit(data_sintomas_extra)\n",
    "#features_to_maintain = [column for column in data_sintomas_extra.columns if column not in drop_constant.features_to_drop_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropando as colunas com baixa variância\n",
    "#data_sintomas_extra = data_sintomas_extra[features_to_maintain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropando a coluna\n",
    "#data = data.drop(\"OUTRO_DES\", axis = 1)\n",
    "#\n",
    "## Concatenando os dataframes\n",
    "#data = pd.concat([data, data_sintomas_extra], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unir a coluna CLASSI_OUT com a coluna CLASSI_FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando os valores numéricos para os nomes das categorias\n",
    "dict_novas_cat = {1.0:\"Influenza\",\n",
    "                  2.0:\"Outro vírus\",\n",
    "                  3.0:3.0,\n",
    "                  5.0:\"Covid-19\"}\n",
    "\n",
    "# Aplicando a mudança\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].map(dict_novas_cat)\n",
    "\n",
    "# Buscando as classes complementares\n",
    "data.loc[data[\"CLASSI_FIN\"] == 3, \"CLASSI_FIN\"] = data.loc[data[\"CLASSI_FIN\"] == 3, \"CLASSI_OUT\"]\n",
    "\n",
    "# Dropando a coluna CLASSI_OUT\n",
    "data = data.drop(\"CLASSI_OUT\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alterar todos os valores numéricos das colunas para o seu real valor;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando as funções\n",
    "func_estrangeiro = lambda num: \"Sim\" if num == 1 else \"Não\"\n",
    "func_zona = lambda num: \"Urbana\" if num == 1 else (\"Rural\" if num == 2 else (\"Periurbana\" if num == 3 else \"Ignorado\"))\n",
    "func_sintoma_and_vacina = lambda num: \"Sim\" if num == 1 else (\"Não\" if num == 2 else \"Ignorado\")\n",
    "\n",
    "# Aplicando as alterações\n",
    "data[\"ESTRANG\"] = data[\"ESTRANG\"].apply(func_estrangeiro)\n",
    "data[\"CS_ZONA\"] = data[\"CS_ZONA\"].apply(func_zona)\n",
    "\n",
    "# Criando uma lista com os sintomas\n",
    "sintomas = [\"FEBRE\", \"TOSSE\", \"GARGANTA\", \"DISPNEIA\", \"DESC_RESP\", \"SATURACAO\", \n",
    "            \"DIARREIA\", \"VOMITO\", \"DOR_ABD\", \"FADIGA\", \"PERD_OLFT\", \n",
    "            \"PERD_PALA\", \"OUTRO_SIN\"]\n",
    "\n",
    "# Aplicando as alterações\n",
    "for sintoma in sintomas:\n",
    "    data[sintoma] = data[sintoma].apply(func_sintoma_and_vacina)\n",
    "    \n",
    "# Criando uma lista com as vacinas\n",
    "vacinas = [\"VACINA\", \"VACINA_COV\"]\n",
    "for vacina in vacinas:\n",
    "    data[vacina] = data[vacina].apply(func_sintoma_and_vacina)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrigir os valores  e ausentes da coluna CLASSI_FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletando os targets ausentes\n",
    "data = data.dropna(subset=[\"CLASSI_FIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonias = [\"pneumonia\", \"PNEUMONIA COMUNITARIA\", \n",
    "              \"broncopnm em paciente com enfi\", \"klebsiella pneumonie\", \n",
    "              \"PNEUMONITE BRONCOASPIRATIVA\", \"PNEUMONITE DEVIDA A ALIMENTO\",\n",
    "              \"DPOC , PNM BRONCOASPIRATIVA\", \"SINDROME GRIPAL, BRONQUIOPNEUM\",\n",
    "              \"PNM BACTERIANA GRAN NEGAT\", \"PNM - IRA\", \"PNM INTRAHOSPITALAR\",\n",
    "              \"PNM , IRPA\", \"PNEMUMONIA\", \"PNEUMOCYSTIS JIROVECII\", \n",
    "              \"PN BACTERIANA\", \"PNM FUNGICA\", \"PNM NOSOCOMIAL AVC\", \"PMEUMONIA\",\n",
    "              \"PNEUMONIO COMUNITARIA\", \"PNM BACTERIANA BRONCOASPIRATIV\", \n",
    "              \"PNEUMINA\", \"PNEUMONIA BACTERIANA\", \"PNEUMONIA - DPOC\",\n",
    "              \"PNEUMONIA BACTERIA\", \"PNEUMONIA NAO ESPECIFICADA J18\",\n",
    "              \"CID J18, PNEUMONIA\", \"BRONCOESPASMO/PNEUMONIA\", \n",
    "              \"MYCOPLASMA PNEUMONIAE\", \"STREPTOCOCCUS PNEUMOIAL\", \n",
    "              \"PNM INTRA HOSPITALASR\", \"PNEUMONIA CID J18, BRONQUIOLIT\",\n",
    "              \"SRAG - PNEUMOCISTOSE\", \"PNEUMONIA POR STAPHYLO AUREUS\", \n",
    "              \"SEPSES PULMONAR, PNEUMONIA ,\", \"PNEUMONIA, CA\", \n",
    "              \"PNEUMONIA, ASMA\", \"PNEUMONIA BACTERIANA NAO ESPEC\", \n",
    "              \"CID= J18 PNEUMONIA\", \"PNEMOCISTOSE.PNEUMONIA POR CMV\", \n",
    "              \"PNEUMON IA\", \"IRA - PNEUMONIA\", \"IRA - PNEUMONIA\",\n",
    "              \"PNEUMONIA - BRONCOESPASMO\", \"PNM VIRAL/ COINF. BACTERIANA\", \n",
    "              \"IRA,PNM\", \"PNEUMONIA\", \"STREPTOCOCCUS PNEUMONIAE\", \"PNM\",\n",
    "              \"PNEUMONIA VIRAL\", \"PNM BACTERIANA\", \"PNEUMONIA NAO ESPECIFICADA\"]\n",
    "\n",
    "covids = [\"Covid-19\", \"CORNOVIRUS OC43\", \"CORONAVIRUS NL63\", \"\"]\n",
    "\n",
    "influenzas = [\"Influenza\", \"H1N1\", \"HAEMOFILOS INFLUENZA\", \"H INFLUENZAE\"]\n",
    "\n",
    "tuberculoses = [\"TUBERCULOSE\", \"MYCOBACTERIUM TUBERCULOSIS\", \n",
    "                \"MICROBACTERIA TUBERCULOSE\", \"TEBERCULOSE\", \n",
    "                \"MYCOBACTERIUM TUBERCULOSIS,\", \"TUBERCULOSE (M. TUBERCULOSIS)\",\n",
    "                \"TUBERCULOSE POSITIVO BAAR\", \"MYCOBACTERIUM TUBERCULOSIS\", \"TB\",\n",
    "                \"TUBERCULOSE PULMONAR\"]\n",
    "\n",
    "vsr = [\"VIRUS SINCICIAL RESPIRATORIO]\", \"VIRUS SINCIAL RESPIRATORIO\",\n",
    "       \"VIRUS SINCICIAL RESPIRATORIO\", \"VIRUS SINCICIAL\"]\n",
    "\n",
    "\n",
    "outros = [\"Outro vírus\", \"HIV\", \"DENGUE\"]\n",
    "\n",
    "# Criando funções para agrupar agentes semelhantes\n",
    "func_agrupar_pneumonia = lambda doenca: \"Pneumonia\" if doenca in pneumonias else doenca\n",
    "func_agrupar_covid = lambda doenca: \"Covid-19\" if doenca in covids else doenca\n",
    "func_agrupar_influenza = lambda doenca: \"Influenza\" if doenca in influenzas else doenca\n",
    "func_agrupar_tuberculose = lambda doenca: \"Tuberculose\" if doenca in tuberculoses else doenca\n",
    "func_agrupar_vsr = lambda doenca: \"VSR\" if doenca in vsr else doenca\n",
    "func_agrupar_outros = lambda doenca: \"Outro vírus\" if doenca in outros else doenca\n",
    "\n",
    "# Aplicando as funções\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].apply(func_agrupar_pneumonia)\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].apply(func_agrupar_covid)\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].apply(func_agrupar_influenza)\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].apply(func_agrupar_tuberculose)\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].apply(func_agrupar_vsr)\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].apply(func_agrupar_outros)\n",
    "\n",
    "# Capturando apenas os registros com doenças conhecidas\n",
    "data = data.query(f\"CLASSI_FIN in {['Pneumonia', 'Covid-19', 'Influenza', 'Tuberculose', 'VSR', 'Outro vírus']}\")\n",
    "\n",
    "# Mapeia o target para numérico\n",
    "dict_target = {\"Pneumonia\":0, \"Covid-19\":1, \"Influenza\":2, \"Tuberculose\":3, \"VSR\":4, \"Outro vírus\":5}\n",
    "data[\"CLASSI_FIN\"] = data[\"CLASSI_FIN\"].map(dict_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engenharia de Features\n",
    "\n",
    "Aqui, irei criar as seguintes features:\n",
    "- Tempo decorrido entre os primeiros sintomas e a notificação;\n",
    "- Tempo decorrido entre a vacinação da gripe e os primeiros sintomas;\n",
    "- Diferença entre a data dos primeiros sintomas e a data de reforço para covid;\n",
    "- Verificar de qual região é o estado do paciente;\n",
    "- Se ele apresenta multiplos sintomas;\n",
    "- Mês do primeiro sintoma e da vacina;\n",
    "- Se os sintomas apareceram na primeira ou segunda quinzena do mês;\n",
    "- Se a vacina foi na primeira ou segunda quinzena do mês;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a diferença entre as semanas epidemiológicas\n",
    "data[\"diferenca_semana_epi\"] = data[\"SEM_NOT\"] - data[\"SEM_PRI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculando a diferença de dias entre a data de vacinação da covid e a data de sintomas\n",
    "data['DIFERENCA_DIAS_REF_COVID'] = (data['DT_SIN_PRI'] - data['DOSE_2REF']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT_SIN_PRI</th>\n",
       "      <th>SEM_PRI</th>\n",
       "      <th>ESTRANG</th>\n",
       "      <th>SEM_NOT</th>\n",
       "      <th>NU_IDADE_N</th>\n",
       "      <th>SG_UF</th>\n",
       "      <th>CS_ZONA</th>\n",
       "      <th>FEBRE</th>\n",
       "      <th>TOSSE</th>\n",
       "      <th>GARGANTA</th>\n",
       "      <th>...</th>\n",
       "      <th>FADIGA</th>\n",
       "      <th>PERD_OLFT</th>\n",
       "      <th>PERD_PALA</th>\n",
       "      <th>OUTRO_SIN</th>\n",
       "      <th>VACINA</th>\n",
       "      <th>VACINA_COV</th>\n",
       "      <th>DOSE_2REF</th>\n",
       "      <th>CLASSI_FIN</th>\n",
       "      <th>diferenca_semana_epi</th>\n",
       "      <th>DIFERENCA_DIAS_REF_COVID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>SP</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>...</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Ignorado</td>\n",
       "      <td>Sim</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>8</td>\n",
       "      <td>Não</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>PR</td>\n",
       "      <td>Ignorado</td>\n",
       "      <td>Ignorado</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Ignorado</td>\n",
       "      <td>...</td>\n",
       "      <td>Ignorado</td>\n",
       "      <td>Ignorado</td>\n",
       "      <td>Ignorado</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Ignorado</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>7</td>\n",
       "      <td>Não</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>PR</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>...</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Ignorado</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-02-08</td>\n",
       "      <td>6</td>\n",
       "      <td>Não</td>\n",
       "      <td>7</td>\n",
       "      <td>89</td>\n",
       "      <td>SP</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>...</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Ignorado</td>\n",
       "      <td>Sim</td>\n",
       "      <td>2022-04-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-03-12</td>\n",
       "      <td>11</td>\n",
       "      <td>Não</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>DF</td>\n",
       "      <td>Urbana</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Sim</td>\n",
       "      <td>Não</td>\n",
       "      <td>...</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Ignorado</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DT_SIN_PRI  SEM_PRI ESTRANG  SEM_NOT  NU_IDADE_N SG_UF   CS_ZONA     FEBRE  \\\n",
       "2  2023-01-05        1     Não        2          72    SP    Urbana       Não   \n",
       "7  2023-02-22        8     Não        8           4    PR  Ignorado  Ignorado   \n",
       "11 2023-02-13        7     Não        7           3    PR    Urbana       Não   \n",
       "16 2023-02-08        6     Não        7          89    SP    Urbana       Sim   \n",
       "18 2023-03-12       11     Não       11           5    DF    Urbana       Sim   \n",
       "\n",
       "   TOSSE  GARGANTA  ...    FADIGA PERD_OLFT PERD_PALA OUTRO_SIN    VACINA  \\\n",
       "2    Sim       Não  ...       Não       Não       Não       Não  Ignorado   \n",
       "7    Sim  Ignorado  ...  Ignorado  Ignorado  Ignorado       Sim  Ignorado   \n",
       "11   Sim       Não  ...       Não       Não       Não       Não  Ignorado   \n",
       "16   Sim       Não  ...       Não       Não       Não       Não  Ignorado   \n",
       "18   Sim       Não  ...       Não       Não       Não       Não  Ignorado   \n",
       "\n",
       "   VACINA_COV  DOSE_2REF CLASSI_FIN diferenca_semana_epi  \\\n",
       "2         Sim 2022-04-19          1                    1   \n",
       "7         Não        NaT          5                    0   \n",
       "11        Não        NaT          5                    0   \n",
       "16        Sim 2022-04-02          1                    1   \n",
       "18        Não        NaT          5                    0   \n",
       "\n",
       "   DIFERENCA_DIAS_REF_COVID  \n",
       "2                     261.0  \n",
       "7                       NaN  \n",
       "11                      NaN  \n",
       "16                    312.0  \n",
       "18                      NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista com as UF de cada região\n",
    "regiao_sul = [\"PR\", \"SC\", \"RS\"]\n",
    "regiao_sudeste = [\"SP\", \"RJ\", \"MG\", \"ES\"]\n",
    "regiao_centro_oeste = [\"MS\", \"MT\", \"GO\", \"DF\"]\n",
    "regiao_norte = [\"RO\", \"AC\", \"AM\", \"RR\", \"PA\", \"AP\", \"TO\"]\n",
    "\n",
    "# Criando uma função para identificar a região\n",
    "func_regiao = lambda uf: \"Sul\" if uf in regiao_sul else(\"Sudeste\" if uf in regiao_sudeste else(\"Centro-Oeste\" if uf in regiao_centro_oeste else(\"Norte\" if uf in regiao_norte else \"Nordeste\")))\n",
    "data[\"REGIAO\"] = data[\"SG_UF\"].apply(func_regiao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contando a quantidade de sintomas que o paciente apresentou\n",
    "data[\"MAIS_DE_UM_SINTOMA\"] = data[sintomas].apply(lambda x: x.str.contains(\"Sim\").sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletando o mês\n",
    "data[\"MES_SIN\"] = data[\"DT_SIN_PRI\"].dt.month\n",
    "data[\"MES_VAC\"] = data[\"DOSE_2REF\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se o dia dos sintomas foi na primeira ou segunda quinzena do mês\n",
    "data[\"QUINZENA_SIN\"] = data[\"DT_SIN_PRI\"].apply(lambda x: \"Primeira\" if x.day <= 15 else \"Segunda\")\n",
    "data[\"QUINZENA_VAC\"] = data[\"DOSE_2REF\"].apply(lambda x: \"Primeira\" if x.day <= 15 else \"Segunda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando as colunas de data\n",
    "data = data.drop([\"DT_SIN_PRI\", \"DOSE_2REF\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o local para salvar os exoerimentos\n",
    "mlflow.set_tracking_uri('../mlruns')\n",
    "\n",
    "## Criando/acessando o experimento\n",
    "#mlflow.set_experiment('Comparando modelos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em variáveis dependentes e independentes\n",
    "x = data.drop(columns='CLASSI_FIN')\n",
    "y = data['CLASSI_FIN']\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x,\n",
    "                                                        y,\n",
    "                                                        test_size=0.30,\n",
    "                                                        random_state=200)\n",
    "\n",
    "# Dividindo os dados em teste e calibração\n",
    "x_teste, x_calib, y_teste, y_calib = train_test_split(x_teste,\n",
    "                                                      y_teste,\n",
    "                                                      test_size=0.35,\n",
    "                                                      random_state=200)\n",
    "\n",
    "# Dividindo os dados em dev e teste\n",
    "x_dev, x_teste, y_dev, y_teste = train_test_split(x_teste,\n",
    "                                                  y_teste,\n",
    "                                                  test_size=0.50,\n",
    "                                                  random_state=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo as colunas categóricas\n",
    "cat_cols = x.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Obtendo as colunas numéricas\n",
    "num_cols = x.select_dtypes(['int', 'float']).columns.tolist()\n",
    "\n",
    "# Instanciando um KFold Estratificado\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dicionário com os modelos\n",
    "dict_models_scale_sensitive = {\"LR\": LogisticRegression(random_state=200,\n",
    "                                                        class_weight='balanced',\n",
    "                                                        multi_class='multinomial')}\n",
    "\n",
    "dict_models_tree_based = {\"LGBM\": LGBMClassifier(is_unbalance=True,\n",
    "                                                 objective= 'multiclass',\n",
    "                                                 random_state=200),\n",
    "                          \"XGB\": XGBClassifier(random_state=200,\n",
    "                                               objective='multi:softprob'),\n",
    "                          \"RF\": RandomForestClassifier(class_weight='balanced',\n",
    "                                                       random_state=200)}\n",
    "\n",
    "# Criando dicionário com os encoders\n",
    "dict_encoders = {\"OHE\": OneHotEncoder(drop='first'),\n",
    "                 \"TE\": ce.TargetEncoder(),\n",
    "                 \"BE\": ce.BinaryEncoder(),\n",
    "                 \"ME\": ce.MEstimateEncoder(),\n",
    "                 \"CE\": ce.CatBoostEncoder(),\n",
    "                 \"GE\":ce.GrayEncoder()}\n",
    "\n",
    "dict_imputers_num = {\"SIAVG\": SimpleImputer(strategy='mean'),\n",
    "                     \"SIMEDIAN\": SimpleImputer(strategy='median')}\n",
    "\n",
    "dict_scalers = {\"SS\": StandardScaler()}\n",
    "\n",
    "# Criando dicionário com os transformers\n",
    "dict_transformers = {\"PT\": PowerTransformer(),\n",
    "                     \"PF\": PolynomialFeatures()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos sem transformers\n",
    "#for tag, model in dict_models_scale_sensitive.items():\n",
    "#    for tag_imputer, imputer in dict_imputers_num.items():\n",
    "#        for tag_encoder, encoder in dict_encoders.items():\n",
    "#            for tag_scaler, scaler in dict_scalers.items():\n",
    "#                \n",
    "#                # Gerando a tag de identificação do modelo\n",
    "#                nome_modelo = f'{tag}_{tag_imputer}_{tag_encoder}_{tag_scaler}'\n",
    "#                \n",
    "#                with mlflow.start_run(run_name=nome_modelo):\n",
    "#                    \n",
    "#                    # Criando os pipeline com os transformers\n",
    "#                    pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                                         ('encoder', encoder)])\n",
    "#                    \n",
    "#                    pipe_num = Pipeline([('imputer_num', imputer),\n",
    "#                                         ('scaler', scaler)])\n",
    "#                    \n",
    "#                    # Criando o transformador\n",
    "#                    transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                    ('num', pipe_num, num_cols)])\n",
    "#                    \n",
    "#                    # Criando o pipeline final\n",
    "#                    pipe = Pipeline([('transformer', transformer),\n",
    "#                                    ('model', model)])\n",
    "#                    \n",
    "#                    # Executando o cross validation\n",
    "#                    cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#                    \n",
    "#                    # Calculando a média das métricas\n",
    "#                    mean_score = cross_val_scores.mean()           \n",
    "#                    \n",
    "#                    # Salvando a métrica da folder 1\n",
    "#                    mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#                    \n",
    "#                    # Salvando a métrica da folder 2\n",
    "#                    mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#                    \n",
    "#                    # Salvando a métrica da folder 3\n",
    "#                    mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#                    \n",
    "#                    # Salvando a métrica da folder 4\n",
    "#                    mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#                    \n",
    "#                    # Salvando a métrica da folder 5\n",
    "#                    mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#                    \n",
    "#                    # Salvando as métricas\n",
    "#                    mlflow.log_metric('log_loss_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos com transformers\n",
    "#for tag, model in dict_models_scale_sensitive.items():\n",
    "#    for tag_imputer, imputer in dict_imputers_num.items():\n",
    "#        for tag_encoder, encoder in dict_encoders.items():\n",
    "#            for tag_scaler, scaler in dict_scalers.items():\n",
    "#                for tag_transformer, transformer in dict_transformers.items():\n",
    "#                \n",
    "#                    # Gerando a tag de identificação do modelo\n",
    "#                    nome_modelo = f'{tag}_{tag_imputer}_{tag_encoder}_{tag_scaler}_{tag_transformer}'\n",
    "#\n",
    "#                    with mlflow.start_run(run_name=nome_modelo):\n",
    "#                        \n",
    "#                        # Criando os pipeline com os transformers\n",
    "#                        pipe_cat = Pipeline([(\"imputer_cat\", SimpleImputer(strategy='most_frequent')),\n",
    "#                                             ('encoder', encoder)])\n",
    "#                    \n",
    "#                        pipe_num = Pipeline([('imputer_num', imputer),\n",
    "#                                             ('scaler', scaler),\n",
    "#                                             ('transformer', transformer)])\n",
    "#\n",
    "#                        # Criando o transformador\n",
    "#                        transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                        ('num', pipe_num, num_cols)])\n",
    "#\n",
    "#                        # Criando o pipeline final\n",
    "#                        pipe = Pipeline([('transformer', transformer),\n",
    "#                                        ('model', model)])\n",
    "#\n",
    "#                        # Executando o cross validation\n",
    "#                        cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#\n",
    "#                        # Calculando a média das métricas\n",
    "#                        mean_score = cross_val_scores.mean()         \n",
    "#\n",
    "#                        # Salvando a métrica da folder 1\n",
    "#                        mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#\n",
    "#                        # Salvando a métrica da folder 2\n",
    "#                        mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#\n",
    "#                        # Salvando a métrica da folder 3\n",
    "#                        mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#\n",
    "#                        # Salvando a métrica da folder 4\n",
    "#                        mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#\n",
    "#                        # Salvando a métrica da folder 5\n",
    "#                        mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#\n",
    "#                        # Salvando as métricas\n",
    "#                        mlflow.log_metric('log_loss_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iniciando os experimentos sem transformers\n",
    "#for tag, model in dict_models_tree_based.items():\n",
    "#    for tag_imputer, imputer in dict_imputers_num.items():\n",
    "#        for tag_encoder, encoder in dict_encoders.items():\n",
    "#\n",
    "#                # Gerando a tag de identificação do modelo\n",
    "#                nome_modelo = f'{tag}_{tag_imputer}_{tag_encoder}'\n",
    "#\n",
    "#                with mlflow.start_run(run_name=nome_modelo):\n",
    "#\n",
    "#                     # Criando os pipeline com os transformers\n",
    "#                     pipe_cat = Pipeline([('imputer_cat', SimpleImputer(strategy='most_frequent')),\n",
    "#                                          ('encoder', encoder)])\n",
    "#                     pipe_num = Pipeline([('imputer_num', imputer)])\n",
    "#\n",
    "#                     # Criando o transformador\n",
    "#                     transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                                      ('num', pipe_num, num_cols)])\n",
    "#\n",
    "#                     # Criando o pipeline final\n",
    "#                     pipe = Pipeline([('transformer', transformer),\n",
    "#                                     ('model', model)])\n",
    "#\n",
    "#                     # Executando o cross validation\n",
    "#                     cross_val_scores = cross_val_score(pipe, x_treino, y_treino, cv=kf, scoring='neg_log_loss')\n",
    "#\n",
    "#                     # Calculando a média das métricas\n",
    "#                     mean_score = cross_val_scores.mean()         \n",
    "#\n",
    "#                     # Salvando a métrica da folder 1\n",
    "#                     mlflow.log_metric('log_loss_fold_1', cross_val_scores[0])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 2\n",
    "#                     mlflow.log_metric('log_loss_fold_2', cross_val_scores[1])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 3\n",
    "#                     mlflow.log_metric('log_loss_fold_3', cross_val_scores[2])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 4\n",
    "#                     mlflow.log_metric('log_loss_fold_4', cross_val_scores[3])\n",
    "#\n",
    "#                     # Salvando a métrica da folder 5\n",
    "#                     mlflow.log_metric('log_loss_fold_5', cross_val_scores[4])\n",
    "#\n",
    "#                     # Salvando as métricas\n",
    "#                     mlflow.log_metric('log_loss_mean', mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Busca a tabela com os resultados\n",
    "#resultados = mlflow.search_runs()\n",
    "#\n",
    "## calculando o tempo de treinamento em segundos\n",
    "#resultados['train_time_em_segundos'] = (resultados['end_time'] - resultados['start_time']).dt.seconds\n",
    "#\n",
    "## Buscando as colunas para retornar\n",
    "#colunas_para_retornar = ['tags.mlflow.runName', 'train_time_em_segundos', \n",
    "#                         'metrics.log_loss_fold_1', 'metrics.log_loss_fold_2', \n",
    "#                         'metrics.log_loss_fold_5', 'metrics.log_loss_fold_3', \n",
    "#                         'metrics.log_loss_fold_4', 'metrics.log_loss_mean']\n",
    "## Retornando os resultados ordenados pela média\n",
    "#resultados.loc[:, colunas_para_retornar].sort_values(by='metrics.log_loss_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E o nosso modelo campeão foi o **XGBoost** com uma média de **0.59** de \n",
    "<i>log loss</i>. O modelo foi acompanhado com os seguintes transformers:\n",
    "**OneHotEncoder** e **SimpleImputer** usando a **mediana**. Foi \n",
    "possível observar que todas as folds possuem um resultado muito próximo, o que \n",
    "indica que o modelo não está sofrendo de overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunando o modelo vencedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criando função para tunar o modelo\n",
    "#def objective(trial):\n",
    "#\n",
    "#    params = {\n",
    "#            'objective':'multi:softprob',\n",
    "#            'eval_metric': 'logloss',\n",
    "#            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "#            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "#            'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "#            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "#            'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "#            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1)\n",
    "#        }\n",
    "#    \n",
    "#    # Criando os pipelines com os transformers\n",
    "#    pipe_cat = Pipeline([('imputer_cat', SimpleImputer(strategy='most_frequent')),\n",
    "#                        ('encoder', OneHotEncoder(drop='first'))])\n",
    "#    \n",
    "#    pipe_num = Pipeline([('imputer_num', SimpleImputer(strategy='mean'))])\n",
    "#\n",
    "#    # Criando o transformador\n",
    "#    transformer = ColumnTransformer([('cat', pipe_cat, cat_cols),\n",
    "#                                     ('num', pipe_num, num_cols)])\n",
    "#\n",
    "#    # Criando o pipeline final\n",
    "#    pipe = Pipeline([('transformer', transformer),\n",
    "#                    ('rf', XGBClassifier(**params))])\n",
    "#\n",
    "#    # Treinando o modelo com os dados de treino\n",
    "#    pipe.fit(x_treino, y_treino)\n",
    "#   \n",
    "#    # Calculando a loss com os dados de desenvolvimento\n",
    "#    logloss = log_loss(y_dev, pipe.predict_proba(x_dev))\n",
    "#    \n",
    "#    return logloss\n",
    "#\n",
    "## Criando o estudo de otimização\n",
    "#study = optuna.create_study(direction = 'minimize')\n",
    "#study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Buscando os melhores parâmetros\n",
    "#study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste Pycaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste 1\n",
    "Modelos sensíveis à escala com standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a9de0_row11_col1, #T_a9de0_row17_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a9de0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a9de0_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_a9de0_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a9de0_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_a9de0_row0_col1\" class=\"data row0 col1\" >200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a9de0_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_a9de0_row1_col1\" class=\"data row1 col1\" >CLASSI_FIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a9de0_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_a9de0_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a9de0_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_a9de0_row3_col1\" class=\"data row3 col1\" >(62304, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a9de0_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_a9de0_row4_col1\" class=\"data row4 col1\" >(62304, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a9de0_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_a9de0_row5_col1\" class=\"data row5 col1\" >(43612, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a9de0_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_a9de0_row6_col1\" class=\"data row6 col1\" >(18692, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_a9de0_row7_col0\" class=\"data row7 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_a9de0_row7_col1\" class=\"data row7 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_a9de0_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_a9de0_row8_col1\" class=\"data row8 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_a9de0_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_a9de0_row9_col1\" class=\"data row9 col1\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_a9de0_row10_col0\" class=\"data row10 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_a9de0_row10_col1\" class=\"data row10 col1\" >83.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_a9de0_row11_col0\" class=\"data row11 col0\" >Preprocess</td>\n",
       "      <td id=\"T_a9de0_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_a9de0_row12_col0\" class=\"data row12 col0\" >Imputation type</td>\n",
       "      <td id=\"T_a9de0_row12_col1\" class=\"data row12 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_a9de0_row13_col0\" class=\"data row13 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_a9de0_row13_col1\" class=\"data row13 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_a9de0_row14_col0\" class=\"data row14 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_a9de0_row14_col1\" class=\"data row14 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_a9de0_row15_col0\" class=\"data row15 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_a9de0_row15_col1\" class=\"data row15 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_a9de0_row16_col0\" class=\"data row16 col0\" >Encoding method</td>\n",
       "      <td id=\"T_a9de0_row16_col1\" class=\"data row16 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_a9de0_row17_col0\" class=\"data row17 col0\" >Normalize</td>\n",
       "      <td id=\"T_a9de0_row17_col1\" class=\"data row17 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_a9de0_row18_col0\" class=\"data row18 col0\" >Normalize method</td>\n",
       "      <td id=\"T_a9de0_row18_col1\" class=\"data row18 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_a9de0_row19_col0\" class=\"data row19 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_a9de0_row19_col1\" class=\"data row19 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_a9de0_row20_col0\" class=\"data row20 col0\" >Fold Number</td>\n",
       "      <td id=\"T_a9de0_row20_col1\" class=\"data row20 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_a9de0_row21_col0\" class=\"data row21 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_a9de0_row21_col1\" class=\"data row21 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_a9de0_row22_col0\" class=\"data row22 col0\" >Use GPU</td>\n",
       "      <td id=\"T_a9de0_row22_col1\" class=\"data row22 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_a9de0_row23_col0\" class=\"data row23 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_a9de0_row23_col1\" class=\"data row23 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_a9de0_row24_col0\" class=\"data row24 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_a9de0_row24_col1\" class=\"data row24 col1\" >Default Scale Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9de0_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_a9de0_row25_col0\" class=\"data row25 col0\" >USI</td>\n",
       "      <td id=\"T_a9de0_row25_col1\" class=\"data row25 col1\" >746e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd8ec400ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/16 14:47:41 INFO mlflow.tracking.fluent: Experiment with name 'Default Scale Sensitive' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name                                                          Log Loss\n",
       "Display Name                                                  Log Loss\n",
       "Score Function       <pycaret.internal.metrics.EncodedDecodedLabels...\n",
       "Scorer               make_scorer(log_loss, greater_is_better=False,...\n",
       "Target                                                      pred_proba\n",
       "Args                                                                {}\n",
       "Greater is Better                                                False\n",
       "Multiclass                                                        True\n",
       "Custom                                                            True\n",
       "Name: logloss, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazendo o setup dos experimentos\n",
    "experimentos_scale_sensitive = setup(data = x_treino.join(y_treino), \n",
    "                     target = 'CLASSI_FIN',\n",
    "                     session_id = 200,\n",
    "                     fold=5,\n",
    "                     normalize=True,\n",
    "                     log_experiment=True,\n",
    "                     experiment_name=\"Default Scale Sensitive\")\n",
    "\n",
    "# Adicioando a Log Loss como métrica\n",
    "add_metric('logloss', 'Log Loss', log_loss, greater_is_better=False, target='pred_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>14:47:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Loading Estimator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   \n",
       "                                                                   \n",
       "Initiated  . . . . . . . . . . . . . . . . . .             14:47:42\n",
       "Status     . . . . . . . . . . . . . . . . . .    Loading Estimator\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  Logistic Regression"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_19729 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_19729_row0_col0, #T_19729_row0_col4, #T_19729_row0_col5, #T_19729_row0_col8, #T_19729_row1_col0, #T_19729_row1_col1, #T_19729_row1_col2, #T_19729_row1_col3, #T_19729_row1_col5, #T_19729_row1_col6, #T_19729_row1_col7, #T_19729_row1_col8, #T_19729_row2_col0, #T_19729_row2_col1, #T_19729_row2_col2, #T_19729_row2_col3, #T_19729_row2_col4, #T_19729_row2_col6, #T_19729_row2_col7, #T_19729_row2_col8, #T_19729_row3_col0, #T_19729_row3_col1, #T_19729_row3_col2, #T_19729_row3_col3, #T_19729_row3_col4, #T_19729_row3_col5, #T_19729_row3_col6, #T_19729_row3_col7, #T_19729_row3_col8, #T_19729_row4_col0, #T_19729_row4_col1, #T_19729_row4_col2, #T_19729_row4_col3, #T_19729_row4_col4, #T_19729_row4_col5, #T_19729_row4_col6, #T_19729_row4_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_19729_row0_col1, #T_19729_row0_col2, #T_19729_row0_col3, #T_19729_row0_col6, #T_19729_row0_col7, #T_19729_row1_col4, #T_19729_row2_col5, #T_19729_row4_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_19729_row0_col9, #T_19729_row2_col9, #T_19729_row3_col9, #T_19729_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_19729_row1_col9 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_19729\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_19729_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_19729_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_19729_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_19729_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_19729_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_19729_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_19729_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_19729_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_19729_level0_col8\" class=\"col_heading level0 col8\" >Log Loss</th>\n",
       "      <th id=\"T_19729_level0_col9\" class=\"col_heading level0 col9\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_19729_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_19729_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_19729_row0_col1\" class=\"data row0 col1\" >0.7439</td>\n",
       "      <td id=\"T_19729_row0_col2\" class=\"data row0 col2\" >0.8603</td>\n",
       "      <td id=\"T_19729_row0_col3\" class=\"data row0 col3\" >0.7439</td>\n",
       "      <td id=\"T_19729_row0_col4\" class=\"data row0 col4\" >0.7054</td>\n",
       "      <td id=\"T_19729_row0_col5\" class=\"data row0 col5\" >0.6984</td>\n",
       "      <td id=\"T_19729_row0_col6\" class=\"data row0 col6\" >0.5604</td>\n",
       "      <td id=\"T_19729_row0_col7\" class=\"data row0 col7\" >0.5758</td>\n",
       "      <td id=\"T_19729_row0_col8\" class=\"data row0 col8\" >0.7184</td>\n",
       "      <td id=\"T_19729_row0_col9\" class=\"data row0 col9\" >5.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19729_level0_row1\" class=\"row_heading level0 row1\" >ridge</th>\n",
       "      <td id=\"T_19729_row1_col0\" class=\"data row1 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_19729_row1_col1\" class=\"data row1 col1\" >0.7386</td>\n",
       "      <td id=\"T_19729_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_19729_row1_col3\" class=\"data row1 col3\" >0.7386</td>\n",
       "      <td id=\"T_19729_row1_col4\" class=\"data row1 col4\" >0.7166</td>\n",
       "      <td id=\"T_19729_row1_col5\" class=\"data row1 col5\" >0.6779</td>\n",
       "      <td id=\"T_19729_row1_col6\" class=\"data row1 col6\" >0.5460</td>\n",
       "      <td id=\"T_19729_row1_col7\" class=\"data row1 col7\" >0.5681</td>\n",
       "      <td id=\"T_19729_row1_col8\" class=\"data row1 col8\" >0.0000</td>\n",
       "      <td id=\"T_19729_row1_col9\" class=\"data row1 col9\" >0.8460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19729_level0_row2\" class=\"row_heading level0 row2\" >lda</th>\n",
       "      <td id=\"T_19729_row2_col0\" class=\"data row2 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_19729_row2_col1\" class=\"data row2 col1\" >0.7381</td>\n",
       "      <td id=\"T_19729_row2_col2\" class=\"data row2 col2\" >0.8571</td>\n",
       "      <td id=\"T_19729_row2_col3\" class=\"data row2 col3\" >0.7381</td>\n",
       "      <td id=\"T_19729_row2_col4\" class=\"data row2 col4\" >0.7037</td>\n",
       "      <td id=\"T_19729_row2_col5\" class=\"data row2 col5\" >0.7069</td>\n",
       "      <td id=\"T_19729_row2_col6\" class=\"data row2 col6\" >0.5565</td>\n",
       "      <td id=\"T_19729_row2_col7\" class=\"data row2 col7\" >0.5664</td>\n",
       "      <td id=\"T_19729_row2_col8\" class=\"data row2 col8\" >0.7543</td>\n",
       "      <td id=\"T_19729_row2_col9\" class=\"data row2 col9\" >1.1360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19729_level0_row3\" class=\"row_heading level0 row3\" >svm</th>\n",
       "      <td id=\"T_19729_row3_col0\" class=\"data row3 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_19729_row3_col1\" class=\"data row3 col1\" >0.7377</td>\n",
       "      <td id=\"T_19729_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n",
       "      <td id=\"T_19729_row3_col3\" class=\"data row3 col3\" >0.7377</td>\n",
       "      <td id=\"T_19729_row3_col4\" class=\"data row3 col4\" >0.6958</td>\n",
       "      <td id=\"T_19729_row3_col5\" class=\"data row3 col5\" >0.6772</td>\n",
       "      <td id=\"T_19729_row3_col6\" class=\"data row3 col6\" >0.5450</td>\n",
       "      <td id=\"T_19729_row3_col7\" class=\"data row3 col7\" >0.5660</td>\n",
       "      <td id=\"T_19729_row3_col8\" class=\"data row3 col8\" >0.0000</td>\n",
       "      <td id=\"T_19729_row3_col9\" class=\"data row3 col9\" >2.3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19729_level0_row4\" class=\"row_heading level0 row4\" >knn</th>\n",
       "      <td id=\"T_19729_row4_col0\" class=\"data row4 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_19729_row4_col1\" class=\"data row4 col1\" >0.6955</td>\n",
       "      <td id=\"T_19729_row4_col2\" class=\"data row4 col2\" >0.8153</td>\n",
       "      <td id=\"T_19729_row4_col3\" class=\"data row4 col3\" >0.6955</td>\n",
       "      <td id=\"T_19729_row4_col4\" class=\"data row4 col4\" >0.6726</td>\n",
       "      <td id=\"T_19729_row4_col5\" class=\"data row4 col5\" >0.6805</td>\n",
       "      <td id=\"T_19729_row4_col6\" class=\"data row4 col6\" >0.4961</td>\n",
       "      <td id=\"T_19729_row4_col7\" class=\"data row4 col7\" >0.4984</td>\n",
       "      <td id=\"T_19729_row4_col8\" class=\"data row4 col8\" >4.0339</td>\n",
       "      <td id=\"T_19729_row4_col9\" class=\"data row4 col9\" >3.8800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd93ee6bb80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criando experimentos apenas com modelos sensíveis a escala dos dados\n",
    "scales_sensitive = compare_models(exclude=['xgboost', 'lightgbm', 'catboost', 'rf', 'gbc', 'et', 'dt', 'ada', 'qda', 'nb', 'dummy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0391f_row5_col0, #T_0391f_row5_col1, #T_0391f_row5_col2, #T_0391f_row5_col3, #T_0391f_row5_col4, #T_0391f_row5_col5, #T_0391f_row5_col6, #T_0391f_row5_col7 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0391f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0391f_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_0391f_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_0391f_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_0391f_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_0391f_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_0391f_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_0391f_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_0391f_level0_col7\" class=\"col_heading level0 col7\" >Log Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0391f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0391f_row0_col0\" class=\"data row0 col0\" >0.7445</td>\n",
       "      <td id=\"T_0391f_row0_col1\" class=\"data row0 col1\" >0.8617</td>\n",
       "      <td id=\"T_0391f_row0_col2\" class=\"data row0 col2\" >0.7445</td>\n",
       "      <td id=\"T_0391f_row0_col3\" class=\"data row0 col3\" >0.7079</td>\n",
       "      <td id=\"T_0391f_row0_col4\" class=\"data row0 col4\" >0.6990</td>\n",
       "      <td id=\"T_0391f_row0_col5\" class=\"data row0 col5\" >0.5612</td>\n",
       "      <td id=\"T_0391f_row0_col6\" class=\"data row0 col6\" >0.5766</td>\n",
       "      <td id=\"T_0391f_row0_col7\" class=\"data row0 col7\" >0.7146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0391f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0391f_row1_col0\" class=\"data row1 col0\" >0.7456</td>\n",
       "      <td id=\"T_0391f_row1_col1\" class=\"data row1 col1\" >0.8624</td>\n",
       "      <td id=\"T_0391f_row1_col2\" class=\"data row1 col2\" >0.7456</td>\n",
       "      <td id=\"T_0391f_row1_col3\" class=\"data row1 col3\" >0.7032</td>\n",
       "      <td id=\"T_0391f_row1_col4\" class=\"data row1 col4\" >0.6996</td>\n",
       "      <td id=\"T_0391f_row1_col5\" class=\"data row1 col5\" >0.5632</td>\n",
       "      <td id=\"T_0391f_row1_col6\" class=\"data row1 col6\" >0.5788</td>\n",
       "      <td id=\"T_0391f_row1_col7\" class=\"data row1 col7\" >0.7124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0391f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0391f_row2_col0\" class=\"data row2 col0\" >0.7402</td>\n",
       "      <td id=\"T_0391f_row2_col1\" class=\"data row2 col1\" >0.8529</td>\n",
       "      <td id=\"T_0391f_row2_col2\" class=\"data row2 col2\" >0.7402</td>\n",
       "      <td id=\"T_0391f_row2_col3\" class=\"data row2 col3\" >0.7046</td>\n",
       "      <td id=\"T_0391f_row2_col4\" class=\"data row2 col4\" >0.6970</td>\n",
       "      <td id=\"T_0391f_row2_col5\" class=\"data row2 col5\" >0.5545</td>\n",
       "      <td id=\"T_0391f_row2_col6\" class=\"data row2 col6\" >0.5693</td>\n",
       "      <td id=\"T_0391f_row2_col7\" class=\"data row2 col7\" >0.7347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0391f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0391f_row3_col0\" class=\"data row3 col0\" >0.7482</td>\n",
       "      <td id=\"T_0391f_row3_col1\" class=\"data row3 col1\" >0.8670</td>\n",
       "      <td id=\"T_0391f_row3_col2\" class=\"data row3 col2\" >0.7482</td>\n",
       "      <td id=\"T_0391f_row3_col3\" class=\"data row3 col3\" >0.7017</td>\n",
       "      <td id=\"T_0391f_row3_col4\" class=\"data row3 col4\" >0.7009</td>\n",
       "      <td id=\"T_0391f_row3_col5\" class=\"data row3 col5\" >0.5678</td>\n",
       "      <td id=\"T_0391f_row3_col6\" class=\"data row3 col6\" >0.5833</td>\n",
       "      <td id=\"T_0391f_row3_col7\" class=\"data row3 col7\" >0.7034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0391f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0391f_row4_col0\" class=\"data row4 col0\" >0.7411</td>\n",
       "      <td id=\"T_0391f_row4_col1\" class=\"data row4 col1\" >0.8575</td>\n",
       "      <td id=\"T_0391f_row4_col2\" class=\"data row4 col2\" >0.7411</td>\n",
       "      <td id=\"T_0391f_row4_col3\" class=\"data row4 col3\" >0.7097</td>\n",
       "      <td id=\"T_0391f_row4_col4\" class=\"data row4 col4\" >0.6956</td>\n",
       "      <td id=\"T_0391f_row4_col5\" class=\"data row4 col5\" >0.5555</td>\n",
       "      <td id=\"T_0391f_row4_col6\" class=\"data row4 col6\" >0.5708</td>\n",
       "      <td id=\"T_0391f_row4_col7\" class=\"data row4 col7\" >0.7270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0391f_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_0391f_row5_col0\" class=\"data row5 col0\" >0.7439</td>\n",
       "      <td id=\"T_0391f_row5_col1\" class=\"data row5 col1\" >0.8603</td>\n",
       "      <td id=\"T_0391f_row5_col2\" class=\"data row5 col2\" >0.7439</td>\n",
       "      <td id=\"T_0391f_row5_col3\" class=\"data row5 col3\" >0.7054</td>\n",
       "      <td id=\"T_0391f_row5_col4\" class=\"data row5 col4\" >0.6984</td>\n",
       "      <td id=\"T_0391f_row5_col5\" class=\"data row5 col5\" >0.5604</td>\n",
       "      <td id=\"T_0391f_row5_col6\" class=\"data row5 col6\" >0.5758</td>\n",
       "      <td id=\"T_0391f_row5_col7\" class=\"data row5 col7\" >0.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0391f_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_0391f_row6_col0\" class=\"data row6 col0\" >0.0029</td>\n",
       "      <td id=\"T_0391f_row6_col1\" class=\"data row6 col1\" >0.0048</td>\n",
       "      <td id=\"T_0391f_row6_col2\" class=\"data row6 col2\" >0.0029</td>\n",
       "      <td id=\"T_0391f_row6_col3\" class=\"data row6 col3\" >0.0030</td>\n",
       "      <td id=\"T_0391f_row6_col4\" class=\"data row6 col4\" >0.0019</td>\n",
       "      <td id=\"T_0391f_row6_col5\" class=\"data row6 col5\" >0.0050</td>\n",
       "      <td id=\"T_0391f_row6_col6\" class=\"data row6 col6\" >0.0052</td>\n",
       "      <td id=\"T_0391f_row6_col7\" class=\"data row6 col7\" >0.0111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd93ee6b790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criando o melhor modelo\n",
    "logistic = create_model('lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As métricas em todas as folds foram muito próximas, o que indica que o modelo\n",
    "não está sofrendo de overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste 2\n",
    "Modelos sensíveis à escala com standard scaler e PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel falhou ao executar o código na célula atual ou em uma célula anterior. Examine o código nas células para identificar uma possível causa da falha. Clique <a href=\"https://aka.ms/vscodeJupyterKernelCrash\">aqui</a> para obter mais informações. Consulte o <a href='command:jupyter.viewOutput'>log</a> do Jupyter para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "# Fazendo o setup dos experimentos\n",
    "experimentos_scale_sensitive = setup(data = x_treino.join(y_treino), \n",
    "                     target = 'CLASSI_FIN',\n",
    "                     session_id = 200,\n",
    "                     fold=5,\n",
    "                     normalize=True,\n",
    "                     polynomial_features=True,\n",
    "                     log_experiment=True,\n",
    "                     experiment_name=\"Scale Sensitive with Polynomial Features\")\n",
    "\n",
    "# Adicioando a Log Loss como métrica\n",
    "add_metric('logloss', 'Log Loss', log_loss, greater_is_better=False, target='pred_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando experimentos apenas com modelos sensíveis a escala dos dados\n",
    "scales_sensitive = compare_models(exclude=['xgboost', 'lightgbm', 'catboost', 'rf', 'gbc', 'et', 'dt', 'ada', 'qda', 'nb', 'dummy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o melhor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste 3\n",
    "Modelos sensíveis à escala com standard scaler e PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo o setup dos experimentos\n",
    "experimentos_scale_sensitive = setup(data = x_treino.join(y_treino), \n",
    "                     target = 'CLASSI_FIN',\n",
    "                     session_id = 200,\n",
    "                     fold=5,\n",
    "                     normalize=True,\n",
    "                     log_experiment=True,\n",
    "                     experiment_name=\"Scale Sensitive with Power Transformer\",\n",
    "                     transformation=True)\n",
    "\n",
    "# Adicioando a Log Loss como métrica\n",
    "add_metric('logloss', 'Log Loss', log_loss, greater_is_better=False, target='pred_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando experimentos apenas com modelos sensíveis a escala dos dados\n",
    "scales_sensitive = compare_models(exclude=['xgboost', 'lightgbm', 'catboost', 'rf', 'gbc', 'et', 'dt', 'ada', 'qda', 'nb', 'dummy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o melhor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conslusão:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste 4\n",
    "Modelos baseados em árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_70ac3_row11_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_70ac3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_70ac3_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_70ac3_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_70ac3_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_70ac3_row0_col1\" class=\"data row0 col1\" >200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_70ac3_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_70ac3_row1_col1\" class=\"data row1 col1\" >CLASSI_FIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_70ac3_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_70ac3_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_70ac3_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_70ac3_row3_col1\" class=\"data row3 col1\" >(62304, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_70ac3_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_70ac3_row4_col1\" class=\"data row4 col1\" >(62304, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_70ac3_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_70ac3_row5_col1\" class=\"data row5 col1\" >(43612, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_70ac3_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_70ac3_row6_col1\" class=\"data row6 col1\" >(18692, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_70ac3_row7_col0\" class=\"data row7 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_70ac3_row7_col1\" class=\"data row7 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_70ac3_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_70ac3_row8_col1\" class=\"data row8 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_70ac3_row9_col0\" class=\"data row9 col0\" >Categorical features</td>\n",
       "      <td id=\"T_70ac3_row9_col1\" class=\"data row9 col1\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_70ac3_row10_col0\" class=\"data row10 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_70ac3_row10_col1\" class=\"data row10 col1\" >83.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_70ac3_row11_col0\" class=\"data row11 col0\" >Preprocess</td>\n",
       "      <td id=\"T_70ac3_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_70ac3_row12_col0\" class=\"data row12 col0\" >Imputation type</td>\n",
       "      <td id=\"T_70ac3_row12_col1\" class=\"data row12 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_70ac3_row13_col0\" class=\"data row13 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_70ac3_row13_col1\" class=\"data row13 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_70ac3_row14_col0\" class=\"data row14 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_70ac3_row14_col1\" class=\"data row14 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_70ac3_row15_col0\" class=\"data row15 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_70ac3_row15_col1\" class=\"data row15 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_70ac3_row16_col0\" class=\"data row16 col0\" >Encoding method</td>\n",
       "      <td id=\"T_70ac3_row16_col1\" class=\"data row16 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_70ac3_row17_col0\" class=\"data row17 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_70ac3_row17_col1\" class=\"data row17 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_70ac3_row18_col0\" class=\"data row18 col0\" >Fold Number</td>\n",
       "      <td id=\"T_70ac3_row18_col1\" class=\"data row18 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_70ac3_row19_col0\" class=\"data row19 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_70ac3_row19_col1\" class=\"data row19 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_70ac3_row20_col0\" class=\"data row20 col0\" >Use GPU</td>\n",
       "      <td id=\"T_70ac3_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_70ac3_row21_col0\" class=\"data row21 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_70ac3_row21_col1\" class=\"data row21 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_70ac3_row22_col0\" class=\"data row22 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_70ac3_row22_col1\" class=\"data row22 col1\" >Default Scale Not Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70ac3_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_70ac3_row23_col0\" class=\"data row23 col0\" >USI</td>\n",
       "      <td id=\"T_70ac3_row23_col1\" class=\"data row23 col1\" >1a55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7efecda9a020>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/15 16:09:54 INFO mlflow.tracking.fluent: Experiment with name 'Default Scale Not Sensitive' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name                                                          Log Loss\n",
       "Display Name                                                  Log Loss\n",
       "Score Function       <pycaret.internal.metrics.EncodedDecodedLabels...\n",
       "Scorer               make_scorer(log_loss, greater_is_better=False,...\n",
       "Target                                                      pred_proba\n",
       "Args                                                                {}\n",
       "Greater is Better                                                False\n",
       "Multiclass                                                        True\n",
       "Custom                                                            True\n",
       "Name: logloss, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazendo o setup dos experimentos\n",
    "experimentos_scale_not_sensitive = setup(data = x_treino.join(y_treino), \n",
    "                     target = 'CLASSI_FIN',\n",
    "                     session_id = 200,\n",
    "                     fold=5,\n",
    "                     log_experiment=True,\n",
    "                     experiment_name=\"Default Scale Not Sensitive\")\n",
    "\n",
    "# Adicioando a Log Loss como métrica\n",
    "add_metric('logloss', 'Log Loss', log_loss, greater_is_better=False, target='pred_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>16:09:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Loading Estimator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 \n",
       "                                                                 \n",
       "Initiated  . . . . . . . . . . . . . . . . . .           16:09:55\n",
       "Status     . . . . . . . . . . . . . . . . . .  Loading Estimator\n",
       "Estimator  . . . . . . . . . . . . . . . . . .        Naive Bayes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_40c65 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_40c65_row0_col0, #T_40c65_row0_col8, #T_40c65_row1_col0, #T_40c65_row1_col1, #T_40c65_row1_col2, #T_40c65_row1_col3, #T_40c65_row1_col4, #T_40c65_row1_col5, #T_40c65_row1_col6, #T_40c65_row1_col7, #T_40c65_row1_col8, #T_40c65_row2_col0, #T_40c65_row2_col1, #T_40c65_row2_col2, #T_40c65_row2_col3, #T_40c65_row2_col4, #T_40c65_row2_col5, #T_40c65_row2_col6, #T_40c65_row2_col7, #T_40c65_row2_col8, #T_40c65_row3_col0, #T_40c65_row3_col1, #T_40c65_row3_col2, #T_40c65_row3_col3, #T_40c65_row3_col4, #T_40c65_row3_col5, #T_40c65_row3_col6, #T_40c65_row3_col7, #T_40c65_row3_col8, #T_40c65_row4_col0, #T_40c65_row4_col1, #T_40c65_row4_col2, #T_40c65_row4_col3, #T_40c65_row4_col4, #T_40c65_row4_col5, #T_40c65_row4_col6, #T_40c65_row4_col7, #T_40c65_row4_col8, #T_40c65_row5_col0, #T_40c65_row5_col1, #T_40c65_row5_col2, #T_40c65_row5_col3, #T_40c65_row5_col4, #T_40c65_row5_col5, #T_40c65_row5_col6, #T_40c65_row5_col7, #T_40c65_row5_col8, #T_40c65_row6_col0, #T_40c65_row6_col1, #T_40c65_row6_col2, #T_40c65_row6_col3, #T_40c65_row6_col4, #T_40c65_row6_col5, #T_40c65_row6_col6, #T_40c65_row6_col7, #T_40c65_row6_col8, #T_40c65_row7_col0, #T_40c65_row7_col1, #T_40c65_row7_col2, #T_40c65_row7_col3, #T_40c65_row7_col4, #T_40c65_row7_col5, #T_40c65_row7_col6, #T_40c65_row7_col7, #T_40c65_row8_col0, #T_40c65_row8_col1, #T_40c65_row8_col2, #T_40c65_row8_col3, #T_40c65_row8_col4, #T_40c65_row8_col5, #T_40c65_row8_col6, #T_40c65_row8_col7, #T_40c65_row8_col8 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_40c65_row0_col1, #T_40c65_row0_col2, #T_40c65_row0_col3, #T_40c65_row0_col4, #T_40c65_row0_col5, #T_40c65_row0_col6, #T_40c65_row0_col7, #T_40c65_row7_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_40c65_row0_col9, #T_40c65_row1_col9, #T_40c65_row2_col9, #T_40c65_row3_col9, #T_40c65_row4_col9, #T_40c65_row5_col9, #T_40c65_row7_col9, #T_40c65_row8_col9 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_40c65_row6_col9 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_40c65\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_40c65_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_40c65_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_40c65_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_40c65_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_40c65_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_40c65_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_40c65_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_40c65_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_40c65_level0_col8\" class=\"col_heading level0 col8\" >Log Loss</th>\n",
       "      <th id=\"T_40c65_level0_col9\" class=\"col_heading level0 col9\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_40c65_level0_row0\" class=\"row_heading level0 row0\" >xgboost</th>\n",
       "      <td id=\"T_40c65_row0_col0\" class=\"data row0 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_40c65_row0_col1\" class=\"data row0 col1\" >0.7768</td>\n",
       "      <td id=\"T_40c65_row0_col2\" class=\"data row0 col2\" >0.9034</td>\n",
       "      <td id=\"T_40c65_row0_col3\" class=\"data row0 col3\" >0.7768</td>\n",
       "      <td id=\"T_40c65_row0_col4\" class=\"data row0 col4\" >0.7628</td>\n",
       "      <td id=\"T_40c65_row0_col5\" class=\"data row0 col5\" >0.7627</td>\n",
       "      <td id=\"T_40c65_row0_col6\" class=\"data row0 col6\" >0.6290</td>\n",
       "      <td id=\"T_40c65_row0_col7\" class=\"data row0 col7\" >0.6334</td>\n",
       "      <td id=\"T_40c65_row0_col8\" class=\"data row0 col8\" >0.6057</td>\n",
       "      <td id=\"T_40c65_row0_col9\" class=\"data row0 col9\" >3.1780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40c65_level0_row1\" class=\"row_heading level0 row1\" >rf</th>\n",
       "      <td id=\"T_40c65_row1_col0\" class=\"data row1 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_40c65_row1_col1\" class=\"data row1 col1\" >0.7699</td>\n",
       "      <td id=\"T_40c65_row1_col2\" class=\"data row1 col2\" >0.8933</td>\n",
       "      <td id=\"T_40c65_row1_col3\" class=\"data row1 col3\" >0.7699</td>\n",
       "      <td id=\"T_40c65_row1_col4\" class=\"data row1 col4\" >0.7519</td>\n",
       "      <td id=\"T_40c65_row1_col5\" class=\"data row1 col5\" >0.7495</td>\n",
       "      <td id=\"T_40c65_row1_col6\" class=\"data row1 col6\" >0.6142</td>\n",
       "      <td id=\"T_40c65_row1_col7\" class=\"data row1 col7\" >0.6206</td>\n",
       "      <td id=\"T_40c65_row1_col8\" class=\"data row1 col8\" >0.8089</td>\n",
       "      <td id=\"T_40c65_row1_col9\" class=\"data row1 col9\" >4.0580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40c65_level0_row2\" class=\"row_heading level0 row2\" >gbc</th>\n",
       "      <td id=\"T_40c65_row2_col0\" class=\"data row2 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_40c65_row2_col1\" class=\"data row2 col1\" >0.7680</td>\n",
       "      <td id=\"T_40c65_row2_col2\" class=\"data row2 col2\" >0.8959</td>\n",
       "      <td id=\"T_40c65_row2_col3\" class=\"data row2 col3\" >0.7680</td>\n",
       "      <td id=\"T_40c65_row2_col4\" class=\"data row2 col4\" >0.7497</td>\n",
       "      <td id=\"T_40c65_row2_col5\" class=\"data row2 col5\" >0.7475</td>\n",
       "      <td id=\"T_40c65_row2_col6\" class=\"data row2 col6\" >0.6107</td>\n",
       "      <td id=\"T_40c65_row2_col7\" class=\"data row2 col7\" >0.6179</td>\n",
       "      <td id=\"T_40c65_row2_col8\" class=\"data row2 col8\" >0.6271</td>\n",
       "      <td id=\"T_40c65_row2_col9\" class=\"data row2 col9\" >25.8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40c65_level0_row3\" class=\"row_heading level0 row3\" >et</th>\n",
       "      <td id=\"T_40c65_row3_col0\" class=\"data row3 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_40c65_row3_col1\" class=\"data row3 col1\" >0.7509</td>\n",
       "      <td id=\"T_40c65_row3_col2\" class=\"data row3 col2\" >0.8794</td>\n",
       "      <td id=\"T_40c65_row3_col3\" class=\"data row3 col3\" >0.7509</td>\n",
       "      <td id=\"T_40c65_row3_col4\" class=\"data row3 col4\" >0.7304</td>\n",
       "      <td id=\"T_40c65_row3_col5\" class=\"data row3 col5\" >0.7332</td>\n",
       "      <td id=\"T_40c65_row3_col6\" class=\"data row3 col6\" >0.5849</td>\n",
       "      <td id=\"T_40c65_row3_col7\" class=\"data row3 col7\" >0.5892</td>\n",
       "      <td id=\"T_40c65_row3_col8\" class=\"data row3 col8\" >1.0073</td>\n",
       "      <td id=\"T_40c65_row3_col9\" class=\"data row3 col9\" >4.8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40c65_level0_row4\" class=\"row_heading level0 row4\" >dt</th>\n",
       "      <td id=\"T_40c65_row4_col0\" class=\"data row4 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_40c65_row4_col1\" class=\"data row4 col1\" >0.6691</td>\n",
       "      <td id=\"T_40c65_row4_col2\" class=\"data row4 col2\" >0.7467</td>\n",
       "      <td id=\"T_40c65_row4_col3\" class=\"data row4 col3\" >0.6691</td>\n",
       "      <td id=\"T_40c65_row4_col4\" class=\"data row4 col4\" >0.6741</td>\n",
       "      <td id=\"T_40c65_row4_col5\" class=\"data row4 col5\" >0.6715</td>\n",
       "      <td id=\"T_40c65_row4_col6\" class=\"data row4 col6\" >0.4716</td>\n",
       "      <td id=\"T_40c65_row4_col7\" class=\"data row4 col7\" >0.4717</td>\n",
       "      <td id=\"T_40c65_row4_col8\" class=\"data row4 col8\" >11.8929</td>\n",
       "      <td id=\"T_40c65_row4_col9\" class=\"data row4 col9\" >1.1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40c65_level0_row5\" class=\"row_heading level0 row5\" >ada</th>\n",
       "      <td id=\"T_40c65_row5_col0\" class=\"data row5 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_40c65_row5_col1\" class=\"data row5 col1\" >0.5872</td>\n",
       "      <td id=\"T_40c65_row5_col2\" class=\"data row5 col2\" >0.6909</td>\n",
       "      <td id=\"T_40c65_row5_col3\" class=\"data row5 col3\" >0.5872</td>\n",
       "      <td id=\"T_40c65_row5_col4\" class=\"data row5 col4\" >0.6845</td>\n",
       "      <td id=\"T_40c65_row5_col5\" class=\"data row5 col5\" >0.5842</td>\n",
       "      <td id=\"T_40c65_row5_col6\" class=\"data row5 col6\" >0.3852</td>\n",
       "      <td id=\"T_40c65_row5_col7\" class=\"data row5 col7\" >0.4045</td>\n",
       "      <td id=\"T_40c65_row5_col8\" class=\"data row5 col8\" >1.6369</td>\n",
       "      <td id=\"T_40c65_row5_col9\" class=\"data row5 col9\" >2.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40c65_level0_row6\" class=\"row_heading level0 row6\" >dummy</th>\n",
       "      <td id=\"T_40c65_row6_col0\" class=\"data row6 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_40c65_row6_col1\" class=\"data row6 col1\" >0.4511</td>\n",
       "      <td id=\"T_40c65_row6_col2\" class=\"data row6 col2\" >0.5000</td>\n",
       "      <td id=\"T_40c65_row6_col3\" class=\"data row6 col3\" >0.4511</td>\n",
       "      <td id=\"T_40c65_row6_col4\" class=\"data row6 col4\" >0.2035</td>\n",
       "      <td id=\"T_40c65_row6_col5\" class=\"data row6 col5\" >0.2805</td>\n",
       "      <td id=\"T_40c65_row6_col6\" class=\"data row6 col6\" >0.0000</td>\n",
       "      <td id=\"T_40c65_row6_col7\" class=\"data row6 col7\" >0.0000</td>\n",
       "      <td id=\"T_40c65_row6_col8\" class=\"data row6 col8\" >1.0699</td>\n",
       "      <td id=\"T_40c65_row6_col9\" class=\"data row6 col9\" >0.7820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40c65_level0_row7\" class=\"row_heading level0 row7\" >qda</th>\n",
       "      <td id=\"T_40c65_row7_col0\" class=\"data row7 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_40c65_row7_col1\" class=\"data row7 col1\" >0.3932</td>\n",
       "      <td id=\"T_40c65_row7_col2\" class=\"data row7 col2\" >0.7455</td>\n",
       "      <td id=\"T_40c65_row7_col3\" class=\"data row7 col3\" >0.3932</td>\n",
       "      <td id=\"T_40c65_row7_col4\" class=\"data row7 col4\" >0.6565</td>\n",
       "      <td id=\"T_40c65_row7_col5\" class=\"data row7 col5\" >0.4564</td>\n",
       "      <td id=\"T_40c65_row7_col6\" class=\"data row7 col6\" >0.2069</td>\n",
       "      <td id=\"T_40c65_row7_col7\" class=\"data row7 col7\" >0.2404</td>\n",
       "      <td id=\"T_40c65_row7_col8\" class=\"data row7 col8\" >12.0883</td>\n",
       "      <td id=\"T_40c65_row7_col9\" class=\"data row7 col9\" >1.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40c65_level0_row8\" class=\"row_heading level0 row8\" >nb</th>\n",
       "      <td id=\"T_40c65_row8_col0\" class=\"data row8 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_40c65_row8_col1\" class=\"data row8 col1\" >0.3093</td>\n",
       "      <td id=\"T_40c65_row8_col2\" class=\"data row8 col2\" >0.6999</td>\n",
       "      <td id=\"T_40c65_row8_col3\" class=\"data row8 col3\" >0.3093</td>\n",
       "      <td id=\"T_40c65_row8_col4\" class=\"data row8 col4\" >0.7165</td>\n",
       "      <td id=\"T_40c65_row8_col5\" class=\"data row8 col5\" >0.4233</td>\n",
       "      <td id=\"T_40c65_row8_col6\" class=\"data row8 col6\" >0.1765</td>\n",
       "      <td id=\"T_40c65_row8_col7\" class=\"data row8 col7\" >0.2105</td>\n",
       "      <td id=\"T_40c65_row8_col8\" class=\"data row8 col8\" >11.8740</td>\n",
       "      <td id=\"T_40c65_row8_col9\" class=\"data row8 col9\" >0.8740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7efecbc0e650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criando experimentos apenas com modelos sensíveis a escala dos dados\n",
    "scales_sensitive = compare_models(exclude=['lr', 'lightgbm', 'catboost', 'ridge', 'lda', 'svm', 'knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7c275_row5_col0, #T_7c275_row5_col1, #T_7c275_row5_col2, #T_7c275_row5_col3, #T_7c275_row5_col4, #T_7c275_row5_col5, #T_7c275_row5_col6, #T_7c275_row5_col7 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7c275\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7c275_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_7c275_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_7c275_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_7c275_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_7c275_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_7c275_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_7c275_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_7c275_level0_col7\" class=\"col_heading level0 col7\" >Log Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7c275_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7c275_row0_col0\" class=\"data row0 col0\" >0.7799</td>\n",
       "      <td id=\"T_7c275_row0_col1\" class=\"data row0 col1\" >0.9050</td>\n",
       "      <td id=\"T_7c275_row0_col2\" class=\"data row0 col2\" >0.7799</td>\n",
       "      <td id=\"T_7c275_row0_col3\" class=\"data row0 col3\" >0.7677</td>\n",
       "      <td id=\"T_7c275_row0_col4\" class=\"data row0 col4\" >0.7662</td>\n",
       "      <td id=\"T_7c275_row0_col5\" class=\"data row0 col5\" >0.6343</td>\n",
       "      <td id=\"T_7c275_row0_col6\" class=\"data row0 col6\" >0.6387</td>\n",
       "      <td id=\"T_7c275_row0_col7\" class=\"data row0 col7\" >0.5983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7c275_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7c275_row1_col0\" class=\"data row1 col0\" >0.7762</td>\n",
       "      <td id=\"T_7c275_row1_col1\" class=\"data row1 col1\" >0.9016</td>\n",
       "      <td id=\"T_7c275_row1_col2\" class=\"data row1 col2\" >0.7762</td>\n",
       "      <td id=\"T_7c275_row1_col3\" class=\"data row1 col3\" >0.7602</td>\n",
       "      <td id=\"T_7c275_row1_col4\" class=\"data row1 col4\" >0.7616</td>\n",
       "      <td id=\"T_7c275_row1_col5\" class=\"data row1 col5\" >0.6278</td>\n",
       "      <td id=\"T_7c275_row1_col6\" class=\"data row1 col6\" >0.6325</td>\n",
       "      <td id=\"T_7c275_row1_col7\" class=\"data row1 col7\" >0.6144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7c275_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7c275_row2_col0\" class=\"data row2 col0\" >0.7702</td>\n",
       "      <td id=\"T_7c275_row2_col1\" class=\"data row2 col1\" >0.9005</td>\n",
       "      <td id=\"T_7c275_row2_col2\" class=\"data row2 col2\" >0.7702</td>\n",
       "      <td id=\"T_7c275_row2_col3\" class=\"data row2 col3\" >0.7558</td>\n",
       "      <td id=\"T_7c275_row2_col4\" class=\"data row2 col4\" >0.7565</td>\n",
       "      <td id=\"T_7c275_row2_col5\" class=\"data row2 col5\" >0.6183</td>\n",
       "      <td id=\"T_7c275_row2_col6\" class=\"data row2 col6\" >0.6227</td>\n",
       "      <td id=\"T_7c275_row2_col7\" class=\"data row2 col7\" >0.6137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7c275_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7c275_row3_col0\" class=\"data row3 col0\" >0.7824</td>\n",
       "      <td id=\"T_7c275_row3_col1\" class=\"data row3 col1\" >0.9093</td>\n",
       "      <td id=\"T_7c275_row3_col2\" class=\"data row3 col2\" >0.7824</td>\n",
       "      <td id=\"T_7c275_row3_col3\" class=\"data row3 col3\" >0.7675</td>\n",
       "      <td id=\"T_7c275_row3_col4\" class=\"data row3 col4\" >0.7674</td>\n",
       "      <td id=\"T_7c275_row3_col5\" class=\"data row3 col5\" >0.6380</td>\n",
       "      <td id=\"T_7c275_row3_col6\" class=\"data row3 col6\" >0.6427</td>\n",
       "      <td id=\"T_7c275_row3_col7\" class=\"data row3 col7\" >0.5901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7c275_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7c275_row4_col0\" class=\"data row4 col0\" >0.7751</td>\n",
       "      <td id=\"T_7c275_row4_col1\" class=\"data row4 col1\" >0.9008</td>\n",
       "      <td id=\"T_7c275_row4_col2\" class=\"data row4 col2\" >0.7751</td>\n",
       "      <td id=\"T_7c275_row4_col3\" class=\"data row4 col3\" >0.7630</td>\n",
       "      <td id=\"T_7c275_row4_col4\" class=\"data row4 col4\" >0.7619</td>\n",
       "      <td id=\"T_7c275_row4_col5\" class=\"data row4 col5\" >0.6263</td>\n",
       "      <td id=\"T_7c275_row4_col6\" class=\"data row4 col6\" >0.6306</td>\n",
       "      <td id=\"T_7c275_row4_col7\" class=\"data row4 col7\" >0.6122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7c275_level0_row5\" class=\"row_heading level0 row5\" >Mean</th>\n",
       "      <td id=\"T_7c275_row5_col0\" class=\"data row5 col0\" >0.7768</td>\n",
       "      <td id=\"T_7c275_row5_col1\" class=\"data row5 col1\" >0.9034</td>\n",
       "      <td id=\"T_7c275_row5_col2\" class=\"data row5 col2\" >0.7768</td>\n",
       "      <td id=\"T_7c275_row5_col3\" class=\"data row5 col3\" >0.7628</td>\n",
       "      <td id=\"T_7c275_row5_col4\" class=\"data row5 col4\" >0.7627</td>\n",
       "      <td id=\"T_7c275_row5_col5\" class=\"data row5 col5\" >0.6290</td>\n",
       "      <td id=\"T_7c275_row5_col6\" class=\"data row5 col6\" >0.6334</td>\n",
       "      <td id=\"T_7c275_row5_col7\" class=\"data row5 col7\" >0.6057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7c275_level0_row6\" class=\"row_heading level0 row6\" >Std</th>\n",
       "      <td id=\"T_7c275_row6_col0\" class=\"data row6 col0\" >0.0042</td>\n",
       "      <td id=\"T_7c275_row6_col1\" class=\"data row6 col1\" >0.0033</td>\n",
       "      <td id=\"T_7c275_row6_col2\" class=\"data row6 col2\" >0.0042</td>\n",
       "      <td id=\"T_7c275_row6_col3\" class=\"data row6 col3\" >0.0045</td>\n",
       "      <td id=\"T_7c275_row6_col4\" class=\"data row6 col4\" >0.0039</td>\n",
       "      <td id=\"T_7c275_row6_col5\" class=\"data row6 col5\" >0.0068</td>\n",
       "      <td id=\"T_7c275_row6_col6\" class=\"data row6 col6\" >0.0069</td>\n",
       "      <td id=\"T_7c275_row6_col7\" class=\"data row6 col7\" >0.0098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7efecbca7700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criando o melhor modelo\n",
    "xgboost = create_model('xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individualmente, os modelos não foram tão bem, com o XGBoost obtendo o melhor\n",
    "resultado. Porém, a Regressão Logística obteve um resultado não tão distante,\n",
    "fazendo com que um ensemble entre os dois modelos seja uma opção."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
